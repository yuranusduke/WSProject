subject#subsubject#subsubsubject#title#authors#abstract#comment
<<<<<<< HEAD
computer science#computing research repository#computer vision and pattern recognition#READ: Large-Scale Neural Scene Rendering for Autonomous Driving#Zhuopeng Li, Lu Li, Zeyu Ma, Ping Zhang, Junbo Chen, Jianke Zhu#"Synthesizing free-view photo-realistic images is an important task in
multimedia. With the development of advanced driver assistance systems~(ADAS)
and their applications in autonomous vehicles, experimenting with different
scenarios becomes a challenge. Although the photo-realistic street scenes can
be synthesized by image-to-image translation methods, which cannot produce
coherent scenes due to the lack of 3D information. In this paper, a large-scale
neural rendering method is proposed to synthesize the autonomous driving
scene~(READ), which makes it possible to synthesize large-scale driving
scenarios on a PC through a variety of sampling schemes. In order to represent
driving scenarios, we propose an {\omega} rendering network to learn neural
descriptors from sparse point clouds. Our model can not only synthesize
realistic driving scenes but also stitch and edit driving scenes. Experiments
show that our model performs well in large-scale driving scenarios."#
computer science#computing research repository#computer vision and pattern recognition#NTIRE 2022 Challenge on Efficient Super-Resolution: Methods and Results#Yawei Li, Kai Zhang, Radu Timofte, Luc Van Gool, Fangyuan Kong, Mingxi Li, Songwei Liu, Zongcai Du, Ding Liu, Chenhui Zhou, Jingyi Chen, Qingrui Han, Zheyuan Li, Yingqi Liu, Xiangyu Chen, Haoming Cai, Yu Qiao, Chao Dong, Long Sun, Jinshan Pan, Yi Zhu, Zhikai Zong, Xiaoxiao Liu, Zheng Hui, Tao Yang, Peiran Ren, Xuansong Xie, Xian-Sheng Hua, Yanbo Wang, Xiaozhong Ji, Chuming Lin, Donghao Luo, Ying Tai, Chengjie Wang, Zhizhong Zhang, Yuan Xie, Shen Cheng, Ziwei Luo, Lei Yu, Zhihong Wen, Qi Wu1, Youwei Li, Haoqiang Fan, Jian Sun, Shuaicheng Liu, Yuanfei Huang, Meiguang Jin, Hua Huang, Jing Liu, Xinjian Zhang, Yan Wang, Lingshun Long, Gen Li, Yuanfan Zhang, Zuowei Cao, Lei Sun, Panaetov Alexander, Yucong Wang, Minjie Cai, Li Wang, Lu Tian, Zheyuan Wang, Hongbing Ma, Jie Liu, Chao Chen, Yidong Cai, Jie Tang, Gangshan Wu, Weiran Wang, Shirui Huang, Honglei Lu, Huan Liu, Keyan Wang, Jun Chen, Shi Chen, Yuchun Miao, Zimo Huang, Lefei Zhang, Mustafa Ayazoğlu, Wei Xiong, Chengyi Xiong, Fei Wang, Hao Li, Ruimian Wen, Zhijing Yang, Wenbin Zou, Weixin Zheng, Tian Ye, Yuncheng Zhang, Xiangzhen Kong, Aditya Arora, Syed Waqas Zamir, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Dandan Gaoand Dengwen Zhouand Qian Ning, Jingzhu Tang, Han Huang, Yufei Wang, Zhangheng Peng, Haobo Li, Wenxue Guan, Shenghua Gong, Xin Li, Jun Liu, Wanjun Wang, Dengwen Zhou, Kun Zeng, Hanjiang Lin, Xinyu Chen, Jinsheng Fang, et al. (11 additional authors not shown)#"This paper reviews the NTIRE 2022 challenge on efficient single image
super-resolution with focus on the proposed solutions and results. The task of
the challenge was to super-resolve an input image with a magnification factor
of $\times$4 based on pairs of low and corresponding high resolution images.
The aim was to design a network for single image super-resolution that achieved
improvement of efficiency measured according to several metrics including
runtime, parameters, FLOPs, activations, and memory consumption while at least
maintaining the PSNR of 29.00dB on DIV2K validation set. IMDN is set as the
baseline for efficiency measurement. The challenge had 3 tracks including the
main track (runtime), sub-track one (model complexity), and sub-track two
(overall performance). In the main track, the practical runtime performance of
the submissions was evaluated. The rank of the teams were determined directly
by the absolute value of the average runtime on the validation set and test
set. In sub-track one, the number of parameters and FLOPs were considered. And
the individual rankings of the two metrics were summed up to determine a final
ranking in this track. In sub-track two, all of the five metrics mentioned in
the description of the challenge including runtime, parameter count, FLOPs,
activations, and memory consumption were considered. Similar to sub-track one,
the rankings of five metrics were summed up to determine a final ranking. The
challenge had 303 registered participants, and 43 teams made valid submissions.
They gauge the state-of-the-art in efficient single image super-resolution."#Validation code of the baseline model is available at . Validation of all submitted models is available at
computer science#computing research repository#computer vision and pattern recognition#TDT: Teaching Detectors to Track without Fully Annotated Videos#Shuzhi Yu, Guanhang Wu, Chunhui Gu, Mohammed E. Fathy#"Recently, one-stage trackers that use a joint model to predict both
detections and appearance embeddings in one forward pass received much
attention and achieved state-of-the-art results on the Multi-Object Tracking
(MOT) benchmarks. However, their success depends on the availability of videos
that are fully annotated with tracking data, which is expensive and hard to
obtain. This can limit the model generalization. In comparison, the two-stage
approach, which performs detection and embedding separately, is slower but
easier to train as their data are easier to annotate. We propose to combine the
best of the two worlds through a data distillation approach. Specifically, we
use a teacher embedder, trained on Re-ID datasets, to generate pseudo
appearance embedding labels for the detection datasets. Then, we use the
augmented dataset to train a detector that is also capable of regressing these
pseudo-embeddings in a fully-convolutional fashion. Our proposed one-stage
solution matches the two-stage counterpart in quality but is 3 times faster.
Even though the teacher embedder has not seen any tracking data during
training, our proposed tracker achieves competitive performance with some
popular trackers (e.g. JDE) trained with fully labeled tracking data."#Workshop on Learning with Limited Labelled Data for Image and Video Understanding (L3D-IVU), CVPR2022 Workshop
computer science#computing research repository#computer vision and pattern recognition#NMR: Neural Manifold Representation for Autonomous Driving#Unnikrishnan R. Nair, Sarthak Sharma, Midhun S. Menon, Srikanth Vidapanakal#"Autonomous driving requires efficient reasoning about the Spatio-temporal
nature of the semantics of the scene. Recent approaches have successfully
amalgamated the traditional modular architecture of an autonomous driving stack
comprising perception, prediction, and planning in an end-to-end trainable
system. Such a system calls for a shared latent space embedding with
interpretable intermediate trainable projected representation. One such
successfully deployed representation is the Bird's-Eye View(BEV) representation
of the scene in ego-frame. However, a fundamental assumption for an undistorted
BEV is the local coplanarity of the world around the ego-vehicle. This
assumption is highly restrictive, as roads, in general, do have gradients. The
resulting distortions make path planning inefficient and incorrect. To overcome
this limitation, we propose Neural Manifold Representation (NMR), a
representation for the task of autonomous driving that learns to infer
semantics and predict way-points on a manifold over a finite horizon, centered
on the ego-vehicle. We do this using an iterative attention mechanism applied
on a latent high dimensional embedding of surround monocular images and partial
ego-vehicle state. This representation helps generate motion and behavior plans
consistent with and cognizant of the surface geometry. We propose a sampling
algorithm based on edge-adaptive coverage loss of BEV occupancy grid and
associated guidance flow field to generate the surface manifold while incurring
minimal computational overhead. We aim to test the efficacy of our approach on
CARLA and SYNTHIA-SF."#
computer science#computing research repository#computer vision and pattern recognition#RepSR: Training Efficient VGG-style Super-Resolution Networks with Structural Re-Parameterization and Batch Normalization#Xintao Wang, Chao Dong, Ying Shan#"This paper explores training efficient VGG-style super-resolution (SR)
networks with the structural re-parameterization technique. The general
pipeline of re-parameterization is to train networks with multi-branch topology
first, and then merge them into standard 3x3 convolutions for efficient
inference. In this work, we revisit those primary designs and investigate
essential components for re-parameterizing SR networks. First of all, we find
that batch normalization (BN) is important to bring training non-linearity and
improve the final performance. However, BN is typically ignored in SR, as it
usually degrades the performance and introduces unpleasant artifacts. We
carefully analyze the cause of BN issue and then propose a straightforward yet
effective solution. In particular, we first train SR networks with mini-batch
statistics as usual, and then switch to using population statistics at the
later training period. While we have successfully re-introduced BN into SR, we
further design a new re-parameterizable block tailored for SR, namely RepSR. It
consists of a clean residual path and two expand-and-squeeze convolution paths
with the modified BN. Extensive experiments demonstrate that our simple RepSR
is capable of achieving superior performance to previous SR re-parameterization
methods among different model sizes. In addition, our RepSR can achieve a
better trade-off between performance and actual running time (throughput) than
previous SR methods. Codes will be available at
."#Technical Report. Codes will be available at
computer science#computing research repository#computer vision and pattern recognition#Video-ReTime: Learning Temporally Varying Speediness for Time Remapping#Simon Jenni, Markus Woodson, Fabian Caba Heilbron#"We propose a method for generating a temporally remapped video that matches
the desired target duration while maximally preserving natural video dynamics.
Our approach trains a neural network through self-supervision to recognize and
accurately localize temporally varying changes in the video playback speed. To
re-time videos, we 1. use the model to infer the slowness of individual video
frames, and 2. optimize the temporal frame sub-sampling to be consistent with
the model's slowness predictions. We demonstrate that this model can detect
playback speed variations more accurately while also being orders of magnitude
more efficient than prior approaches. Furthermore, we propose an optimization
for video re-timing that enables precise control over the target duration and
performs more robustly on longer videos than prior methods. We evaluate the
model quantitatively on artificially speed-up videos, through transfer to
action recognition, and qualitatively through user studies."#Accepted at the AI for Content Creation (AICC) workshop at CVPR 2022
computer science#computing research repository#computer vision and pattern recognition#Revisiting Random Channel Pruning for Neural Network Compression#Yawei Li, Kamil Adamczewski, Wen Li, Shuhang Gu, Radu Timofte, Luc Van Gool#"Channel (or 3D filter) pruning serves as an effective way to accelerate the
inference of neural networks. There has been a flurry of algorithms that try to
solve this practical problem, each being claimed effective in some ways. Yet, a
benchmark to compare those algorithms directly is lacking, mainly due to the
complexity of the algorithms and some custom settings such as the particular
network configuration or training procedure. A fair benchmark is important for
the further development of channel pruning.
Meanwhile, recent investigations reveal that the channel configurations
discovered by pruning algorithms are at least as important as the pre-trained
weights. This gives channel pruning a new role, namely searching the optimal
channel configuration. In this paper, we try to determine the channel
configuration of the pruned models by random search. The proposed approach
provides a new way to compare different methods, namely how well they behave
compared with random pruning. We show that this simple strategy works quite
well compared with other channel pruning methods. We also show that under this
setting, there are surprisingly no clear winners among different channel
importance evaluation methods, which then may tilt the research efforts into
advanced channel configuration searching methods."#Accepted to CVPR2022. Code will be released at \url{}
computer science#computing research repository#computer vision and pattern recognition#An Empirical Study Of Self-supervised Learning Approaches For Object Detection With Transformers#Gokul Karthik Kumar, Sahal Shaji Mullappilly, Abhishek Singh Gehlot#"Self-supervised learning (SSL) methods such as masked language modeling have
shown massive performance gains by pretraining transformer models for a variety
of natural language processing tasks. The follow-up research adapted similar
methods like masked image modeling in vision transformer and demonstrated
improvements in the image classification task. Such simple self-supervised
methods are not exhaustively studied for object detection transformers (DETR,
Deformable DETR) as their transformer encoder modules take input in the
convolutional neural network (CNN) extracted feature space rather than the
image space as in general vision transformers. However, the CNN feature maps
still maintain the spatial relationship and we utilize this property to design
self-supervised learning approaches to train the encoder of object detection
transformers in pretraining and multi-task learning settings. We explore common
self-supervised methods based on image reconstruction, masked image modeling
and jigsaw. Preliminary experiments in the iSAID dataset demonstrate faster
convergence of DETR in the initial epochs in both pretraining and multi-task
learning settings; nonetheless, similar improvement is not observed in the case
of multi-task learning with Deformable DETR. The code for our experiments with
DETR and Deformable DETR are available at 
and  respectively."#"Final Project for the course ""Visual Object Detection And Recognition"" (CV703) at MBZUAI"
computer science#computing research repository#computer vision and pattern recognition#Face Detection on Mobile: Five Implementations and Analysis#Kostiantyn Khabarlak#"In many practical cases face detection on smartphones or other highly
portable devices is a necessity. Applications include mobile face access
control systems, driver status tracking, emotion recognition, etc. Mobile
devices have limited processing power and should have long-enough battery life
even with face detection application running. Thus, striking the right balance
between algorithm quality and complexity is crucial. In this work we adapt 5
algorithms to mobile. These algorithms are based on handcrafted or
neural-network-based features and include: Viola-Jones (Haar cascade), LBP,
HOG, MTCNN, BlazeFace. We analyze inference time of these algorithms on
different devices with different input image resolutions. We provide guidance,
which algorithms are the best fit for mobile face access control systems and
potentially other mobile applications. Interestingly, we note that cascaded
algorithms perform faster on scenes without faces, while BlazeFace is slower on
empty scenes. Exploiting this behavior might be useful in practice."#
computer science#computing research repository#computer vision and pattern recognition#Review on Panoramic Imaging and Its Applications in Scene Understanding#Shaohua Gao, Kailun Yang, Hao Shi, Kaiwei Wang, Jian Bai#"With the rapid development of high-speed communication and artificial
intelligence technologies, human perception of real-world scenes is no longer
limited to the use of small Field of View (FoV) and low-dimensional scene
detection devices. Panoramic imaging emerges as the next generation of
innovative intelligent instruments for environmental perception and
measurement. However, while satisfying the need for large-FoV photographic
imaging, panoramic imaging instruments are expected to have high resolution, no
blind area, miniaturization, and multi-dimensional intelligent perception, and
can be combined with artificial intelligence methods towards the next
generation of intelligent instruments, enabling deeper understanding and more
holistic perception of 360-degree real-world surrounding environments.
Fortunately, recent advances in freeform surfaces, thin-plate optics, and
metasurfaces provide innovative approaches to address human perception of the
environment, offering promising ideas beyond conventional optical imaging. In
this review, we begin with introducing the basic principles of panoramic
imaging systems, and then describe the architectures, features, and functions
of various panoramic imaging systems. Afterwards, we discuss in detail the
broad application prospects and great design potential of freeform surfaces,
thin-plate optics, and metasurfaces in panoramic imaging. We then provide a
detailed analysis on how these techniques can help enhance the performance of
panoramic imaging systems. We further offer a detailed analysis of applications
of panoramic imaging in scene understanding for autonomous driving and
robotics, spanning panoramic semantic image segmentation, panoramic depth
estimation, panoramic visual localization, and so on. Finally, we cast a
perspective on future potential and research directions for panoramic imaging
instruments."#29 pages, 14 figures, 348 references
computer science#computing research repository#computer vision and pattern recognition#HULC: 3D Human Motion Capture with Pose Manifold Sampling and Dense Contact Guidance#Soshi Shimada, Vladislav Golyanik, Patrick Pérez, Weipeng Xu, Christian Theobalt#"Marker-less monocular 3D human motion capture (MoCap) with scene interactions
is a challenging research topic relevant for extended reality, robotics and
virtual avatar generation. Due to the inherent depth ambiguity of monocular
settings, 3D motions captured with existing methods often contain severe
artefacts such as incorrect body-scene inter-penetrations, jitter and body
floating. To tackle these issues, we propose HULC, a new approach for 3D human
MoCap which is aware of the scene geometry. HULC estimates 3D poses and dense
body-environment surface contacts for improved 3D localisations, as well as the
absolute scale of the subject. Furthermore, we introduce a 3D pose trajectory
optimisation based on a novel pose manifold sampling that resolves erroneous
body-environment inter-penetrations. Although the proposed method requires less
structured inputs compared to existing scene-aware monocular MoCap algorithms,
it produces more physically-plausible poses: HULC significantly and
consistently outperforms the existing approaches in various experiments and on
different metrics."#
computer science#computing research repository#computer vision and pattern recognition#RISP: Rendering-Invariant State Predictor with Differentiable Simulation and Rendering for Cross-Domain Parameter Estimation#Pingchuan Ma, Tao Du, Joshua B. Tenenbaum, Wojciech Matusik, Chuang Gan#"This work considers identifying parameters characterizing a physical system's
dynamic motion directly from a video whose rendering configurations are
inaccessible. Existing solutions require massive training data or lack
generalizability to unknown rendering configurations. We propose a novel
approach that marries domain randomization and differentiable rendering
gradients to address this problem. Our core idea is to train a
rendering-invariant state-prediction (RISP) network that transforms image
differences into state differences independent of rendering configurations,
e.g., lighting, shadows, or material reflectance. To train this predictor, we
formulate a new loss on rendering variances using gradients from differentiable
rendering. Moreover, we present an efficient, second-order method to compute
the gradients of this loss, allowing it to be integrated seamlessly into modern
deep learning frameworks. We evaluate our method in rigid-body and
deformable-body simulation environments using four tasks: state estimation,
system identification, imitation learning, and visuomotor control. We further
demonstrate the efficacy of our approach on a real-world example: inferring the
state and action sequences of a quadrotor from a video of its motion sequences.
Compared with existing methods, our approach achieves significantly lower
reconstruction errors and has better generalizability among unknown rendering
configurations."#ICLR Oral. Project page:
computer science#computing research repository#computer vision and pattern recognition#Invisible-to-Visible: Privacy-Aware Human Segmentation using Airborne Ultrasound via Collaborative Learning Probabilistic U-Net#Risako Tanigawa, Yasunori Ishii, Kazuki Kozuka, Takayoshi Yamashita#"Color images are easy to understand visually and can acquire a great deal of
information, such as color and texture. They are highly and widely used in
tasks such as segmentation. On the other hand, in indoor person segmentation,
it is necessary to collect person data considering privacy. We propose a new
task for human segmentation from invisible information, especially airborne
ultrasound. We first convert ultrasound waves to reflected ultrasound
directional images (ultrasound images) to perform segmentation from invisible
information. Although ultrasound images can roughly identify a person's
location, the detailed shape is ambiguous. To address this problem, we propose
a collaborative learning probabilistic U-Net that uses ultrasound and
segmentation images simultaneously during training, closing the probabilistic
distributions between ultrasound and segmentation images by comparing the
parameters of the latent spaces. In inference, only ultrasound images can be
used to obtain segmentation results. As a result of performance verification,
the proposed method could estimate human segmentations more accurately than
conventional probabilistic U-Net and other variational autoencoder models."#arXiv admin note: substantial text overlap with
computer science#computing research repository#computer vision and pattern recognition#Arbitrary Shape Text Detection via Boundary Transformer#Shi-Xue Zhang, Xiaobin Zhu, Chun Yang, Xu-Cheng Yin#"Arbitrary shape text detection is a challenging task due to its complexity
and variety, e.g, various scales, random rotations, and curve shapes. In this
paper, we propose an arbitrary shape text detector with a boundary transformer,
which can accurately and directly locate text boundaries without any
post-processing. Our method mainly consists of a boundary proposal module and
an iteratively optimized boundary transformer module. The boundary proposal
module consisting of multi-layer dilated convolutions will compute important
prior information (including classification map, distance field, and direction
field) for generating coarse boundary proposals meanwhile guiding the
optimization of boundary transformer. The boundary transformer module adopts an
encoder-decoder structure, in which the encoder is constructed by multi-layer
transformer blocks with residual connection while the decoder is a simple
multi-layer perceptron network (MLP). Under the guidance of prior information,
the boundary transformer module will gradually refine the coarse boundary
proposals via boundary deformation in an iterative manner. Furthermore, we
propose a novel boundary energy loss (BEL) which introduces an energy
minimization constraint and an energy monotonically decreasing constraint for
every boundary optimization step. Extensive experiments on publicly available
and challenging datasets demonstrate the state-of-the-art performance and
promising efficiency of our method."#13 pages, 12  is not the final version,just a preview. arXiv admin note: text overlap with
computer science#computing research repository#computer vision and pattern recognition#Deep Depth Completion: A Survey#Junjie Hu, Chenyu Bao, Mete Ozay, Chenyou Fan, Qing Gao, Honghai Liu, Tin Lun Lam#"Depth completion aims at predicting dense pixel-wise depth from a sparse map
captured from a depth sensor. It plays an essential role in various
applications such as autonomous driving, 3D reconstruction, augmented reality,
and robot navigation. Recent successes on the task have been demonstrated and
dominated by deep learning based solutions. In this article, for the first
time, we provide a comprehensive literature review that helps readers better
grasp the research trends and clearly understand the current advances. We
investigate the related studies from the design aspects of network
architectures, loss functions, benchmark datasets, and learning strategies with
a proposal of a novel taxonomy that categorizes existing methods. Besides, we
present a quantitative comparison of model performance on two widely used
benchmark datasets, including an indoor and an outdoor dataset. Finally, we
discuss the challenges of prior works and provide readers with some insights
for future research directions."#
computer science#computing research repository#computer vision and pattern recognition#AutoLC: Search Lightweight and Top-Performing Architecture for Remote Sensing Image Land-Cover Classification#Chenyu Zheng, Junjue Wang, Ailong Ma, Yanfei Zhong#"Land-cover classification has long been a hot and difficult challenge in
remote sensing community. With massive High-resolution Remote Sensing (HRS)
images available, manually and automatically designed Convolutional Neural
Networks (CNNs) have already shown their great latent capacity on HRS
land-cover classification in recent years. Especially, the former can achieve
better performance while the latter is able to generate lightweight
architecture. Unfortunately, they both have shortcomings. On the one hand,
because manual CNNs are almost proposed for natural image processing, it
becomes very redundant and inefficient to process HRS images. On the other
hand, nascent Neural Architecture Search (NAS) techniques for dense prediction
tasks are mainly based on encoder-decoder architecture, and just focus on the
automatic design of the encoder, which makes it still difficult to recover the
refined mapping when confronting complicated HRS scenes.
To overcome their defects and tackle the HRS land-cover classification
problems better, we propose AutoLC which combines the advantages of two
methods. First, we devise a hierarchical search space and gain the lightweight
encoder underlying gradient-based search strategy. Second, we meticulously
design a lightweight but top-performing decoder that is adaptive to the
searched encoder of itself. Finally, experimental results on the LoveDA
land-cover dataset demonstrate that our AutoLC method outperforms the
state-of-art manual and automatic methods with much less computational
consumption."#Early accepted by ICPR 2022
computer science#computing research repository#computer vision and pattern recognition#Recurrent Encoder-Decoder Networks for Vessel Trajectory Prediction with Uncertainty Estimation#Samuele Capobianco, Nicola Forti, Leonardo M. Millefiori, Paolo Braca, Peter Willett#"Recent deep learning methods for vessel trajectory prediction are able to
learn complex maritime patterns from historical Automatic Identification System
(AIS) data and accurately predict sequences of future vessel positions with a
prediction horizon of several hours. However, in maritime surveillance
applications, reliably quantifying the prediction uncertainty can be as
important as obtaining high accuracy. This paper extends deep learning
frameworks for trajectory prediction tasks by exploring how recurrent
encoder-decoder neural networks can be tasked not only to predict but also to
yield a corresponding prediction uncertainty via Bayesian modeling of epistemic
and aleatoric uncertainties. We compare the prediction performance of two
different models based on labeled or unlabeled input data to highlight how
uncertainty quantification and accuracy can be improved by using, if available,
additional information on the intention of the ship (e.g., its planned
destination)."#10 pages, 6 figures
computer science#computing research repository#computer vision and pattern recognition#An Objective Method for Pedestrian Occlusion Level Classification#Shane Gilroy, Martin Glavin, Edward Jones, Darragh Mullins#"Pedestrian detection is among the most safety-critical features of driver
assistance systems for autonomous vehicles. One of the most complex detection
challenges is that of partial occlusion, where a target object is only
partially available to the sensor due to obstruction by another foreground
object. A number of current pedestrian detection benchmarks provide annotation
for partial occlusion to assess algorithm performance in these scenarios,
however each benchmark varies greatly in their definition of the occurrence and
severity of occlusion. In addition, current occlusion level annotation methods
contain a high degree of subjectivity by the human annotator. This can lead to
inaccurate or inconsistent reporting of an algorithm's detection performance
for partially occluded pedestrians, depending on which benchmark is used. This
research presents a novel, objective method for pedestrian occlusion level
classification for ground truth annotation. Occlusion level classification is
achieved through the identification of visible pedestrian keypoints and through
the use of a novel, effective method of 2D body surface area estimation.
Experimental results demonstrate that the proposed method reflects the
pixel-wise occlusion level of pedestrians in images and is effective for all
forms of occlusion, including challenging edge cases such as self-occlusion,
truncation and inter-occluding pedestrians."#
computer science#computing research repository#computer vision and pattern recognition#Multi-Label Logo Recognition and Retrieval based on Weighted Fusion of Neural Features#Marisa Bernabeu, Antonio Javier Gallego, Antonio Pertusa#"Logo classification is a particular case of image classification, since these
may contain only text, images, or a combination of both. In this work, we
propose a system for the multi-label classification and similarity search of
logo images. The method allows obtaining the most similar logos on the basis of
their shape, color, business sector, semantics, general characteristics, or a
combination of such features established by the user. This is done by employing
a set of multi-label networks specialized in certain characteristics of logos.
The features extracted from these networks are combined to perform the
similarity search according to the search criteria established. Since the text
of logos is sometimes irrelevant for the classification, a preprocessing stage
is carried out to remove it, thus improving the overall performance. The
proposed approach is evaluated using the European Union Trademark (EUTM)
dataset, structured with the hierarchical Vienna classification system, which
includes a series of metadata with which to index trademarks. We also make a
comparison between well known logo topologies and Vienna in order to help
designers understand their correspondences. The experimentation carried out
attained reliable performance results, both quantitatively and qualitatively,
which outperformed the state-of-the-art results. In addition, since the
semantics and classification of brands can often be subjective, we also
surveyed graphic design students and professionals in order to assess the
reliability of the proposed method."#
computer science#computing research repository#computer vision and pattern recognition#RustSEG -- Automated segmentation of corrosion using deep learning#B. Burton, W.T. Nash, N. Birbilis#"The inspection of infrastructure for corrosion remains a task that is
typically performed manually by qualified engineers or inspectors. This task of
inspection is laborious, slow, and often requires complex access. Recently,
deep learning based algorithms have revealed promise and performance in the
automatic detection of corrosion. However, to date, research regarding the
segmentation of images for automated corrosion detection has been limited, due
to the lack of availability of per-pixel labelled data sets which are required
for model training. Herein, a novel deep learning approach (termed RustSEG) is
presented, that can accurately segment images for automated corrosion
detection, without the requirement of per-pixel labelled data sets for
training. The RustSEG method will first, using deep learning techniques,
determine if corrosion is present in an image (i.e. a classification task), and
then if corrosion is present, the model will examine what pixels in the
original image contributed to that classification decision. Finally, the method
can refine its predictions into a pixel-level segmentation mask. In ideal
cases, the method is able to generate precise masks of corrosion in images,
demonstrating that the automated segmentation of corrosion without per-pixel
training data is possible, addressing a significant hurdle in automated
infrastructure inspection."#
computer science#computing research repository#computer vision and pattern recognition#A Continual Deepfake Detection Benchmark: Dataset, Methods, and Essentials#Chuqiao Li, Zhiwu Huang, Danda Pani Paudel, Yabin Wang, Mohamad Shahbazi, Xiaopeng Hong, Luc Van Gool#"There have been emerging a number of benchmarks and techniques for the
detection of deepfakes. However, very few works study the detection of
incrementally appearing deepfakes in the real-world scenarios. To simulate the
wild scenes, this paper suggests a continual deepfake detection benchmark
(CDDB) over a new collection of deepfakes from both known and unknown
generative models. The suggested CDDB designs multiple evaluations on the
detection over easy, hard, and long sequence of deepfake tasks, with a set of
appropriate measures. In addition, we exploit multiple approaches to adapt
multiclass incremental learning methods, commonly used in the continual visual
recognition, to the continual deepfake detection problem. We evaluate several
methods, including the adapted ones, on the proposed CDDB. Within the proposed
benchmark, we explore some commonly known essentials of standard continual
learning. Our study provides new insights on these essentials in the context of
continual deepfake detection. The suggested CDDB is clearly more challenging
than the existing benchmarks, which thus offers a suitable evaluation avenue to
the future research. Our benchmark dataset and the source code will be made
publicly available."#
computer science#computing research repository#computer vision and pattern recognition#Transformer-based Cross-Modal Recipe Embeddings with Large Batch Training#Jing Yang, Junwen Chen, Keiji Yanai#"In this paper, we present a cross-modal recipe retrieval framework,
Transformer-based Network for Large Batch Training (TNLBT), which is inspired
by ACME~(Adversarial Cross-Modal Embedding) and H-T~(Hierarchical Transformer).
TNLBT aims to accomplish retrieval tasks while generating images from recipe
embeddings. We apply the Hierarchical Transformer-based recipe text encoder,
the Vision Transformer~(ViT)-based recipe image encoder, and an adversarial
network architecture to enable better cross-modal embedding learning for recipe
texts and images. In addition, we use self-supervised learning to exploit the
rich information in the recipe texts having no corresponding images. Since
contrastive learning could benefit from a larger batch size according to the
recent literature on self-supervised learning, we adopt a large batch size
during training and have validated its effectiveness. In the experiments, the
proposed framework significantly outperformed the current state-of-the-art
frameworks in both cross-modal recipe retrieval and image generation tasks on
the benchmark Recipe1M. This is the first work which confirmed the
effectiveness of large batch training on cross-modal recipe embeddings."#13 pages, 8 figures
computer science#computing research repository#computer vision and pattern recognition#Learning to Answer Visual Questions from Web Videos#Antoine Yang, Antoine Miech, Josef Sivic, Ivan Laptev, Cordelia Schmid#"Recent methods for visual question answering rely on large-scale annotated
datasets. Manual annotation of questions and answers for videos, however, is
tedious, expensive and prevents scalability. In this work, we propose to avoid
manual annotation and generate a large-scale training dataset for video
question answering making use of automatic cross-modal supervision. We leverage
a question generation transformer trained on text data and use it to generate
question-answer pairs from transcribed video narrations. Given narrated videos,
we then automatically generate the HowToVQA69M dataset with 69M
video-question-answer triplets. To handle the open vocabulary of diverse
answers in this dataset, we propose a training procedure based on a contrastive
loss between a video-question multi-modal transformer and an answer
transformer. We introduce the zero-shot VideoQA task and the VideoQA feature
probe evaluation setting and show excellent results, in particular for rare
answers. Furthermore, our method achieves competitive results on MSRVTT-QA,
ActivityNet-QA, MSVD-QA and How2QA datasets. We also show that our VideoQA
dataset generation approach generalizes to another source of web video and text
data. We use our method to generate the WebVidVQA3M dataset from the WebVid
dataset, i.e., videos with alt-text annotations, and show its benefits for
training VideoQA models. Finally, for a detailed evaluation we introduce iVQA,
a new VideoQA dataset with reduced language bias and high-quality manual
annotations. Code, datasets and trained models are available at"#Accepted at the TPAMI Special Issue on the Best Papers of ICCV 2021. Journal extension of the conference paper . 16 pages, 13 figures
computer science#computing research repository#computer vision and pattern recognition#KeypointNeRF: Generalizing Image-based Volumetric Avatars using Relative Spatial Encoding of Keypoints#Marko Mihajlovic, Aayush Bansal, Michael Zollhoefer, Siyu Tang, Shunsuke Saito#"Image-based volumetric avatars using pixel-aligned features promise
generalization to unseen poses and identities. Prior work leverages global
spatial encodings and multi-view geometric consistency to reduce spatial
ambiguity. However, global encodings often suffer from overfitting to the
distribution of the training data, and it is difficult to learn multi-view
consistent reconstruction from sparse views. In this work, we investigate
common issues with existing spatial encodings and propose a simple yet highly
effective approach to modeling high-fidelity volumetric avatars from sparse
views. One of the key ideas is to encode relative spatial 3D information via
sparse 3D keypoints. This approach is robust to the sparsity of viewpoints and
cross-dataset domain gap. Our approach outperforms state-of-the-art methods for
head reconstruction. On human body reconstruction for unseen subjects, we also
achieve performance comparable to prior work that uses a parametric human body
model and temporal feature aggregation. Our experiments show that a majority of
errors in prior work stem from an inappropriate choice of spatial encoding and
thus we suggest a new direction for high-fidelity image-based avatar modeling."#The project page is available at
computer science#computing research repository#computer vision and pattern recognition#Classification and mapping of low-statured 'shrubland' cover types in post-agricultural landscapes of the US Northeast#Michael J Mahoney, Lucas K Johnson, Colin M Beier#"Context: Novel plant communities reshape landscapes and pose challenges for
land cover classification and mapping that can constrain research and
stewardship efforts. In the US Northeast, emergence of low-statured woody
vegetation, or 'shrublands', instead of secondary forests in post-agricultural
landscapes is well-documented by field studies, but poorly understood from a
landscape perspective, which limits the ability to systematically study and
manage these lands. Objectives: To address gaps in classification/mapping of
low-statured cover types where they have been historically rare, we developed
models to predict 'shrubland' distributions at 30m resolution across New York
State (NYS), using machine learning and model ensembling techniques to
integrate remote sensing of structural (airborne LIDAR) and optical (satellite
imagery) properties of vegetation cover. We first classified a 1m canopy height
model (CHM), derived from a ""patchwork"" of available LIDAR coverages, to define
shrubland presence/absence. Next, these non-contiguous maps were used to train
a model ensemble based on temporally-segmented imagery to predict 'shrubland'
probability for the entire study landscape (NYS). Results: Approximately 2.5%
of the CHM coverage area was classified as shrubland. Models using Landsat
predictors trained on the classified CHM were effective at identifying
shrubland (test set AUC=0.893, real-world AUC=0.904), in discriminating between
shrub/young forest and other cover classes, and produced qualitatively sensible
maps, even when extending beyond the original training data. Conclusions: After
ground-truthing, we expect these shrubland maps and models will have many
research and stewardship applications including wildlife conservation, invasive
species mitigation and natural climate solutions."#29 pages (19 main text, 10 supplementary materials); 11 figures (10 main text, 1 supplementary materials), 10 tables (3 main text, 7 supplementary materials). Submitted to Landscape Ecology
computer science#computing research repository#computer vision and pattern recognition#Metric Learning based Interactive Modulation for Real-World Super-Resolution#Chong Mou, Yanze Wu, Xintao Wang, Chao Dong, Jian Zhang, Ying Shan#"Interactive image restoration aims to restore images by adjusting several
controlling coefficients, which determine the restoration strength. Existing
methods are restricted in learning the controllable functions under the
supervision of known degradation types and levels. They usually suffer from a
severe performance drop when the real degradation is different from their
assumptions. Such a limitation is due to the complexity of real-world
degradations, which can not provide explicit supervision to the interactive
modulation during training. However, how to realize the interactive modulation
in real-world super-resolution has not yet been studied. In this work, we
present a Metric Learning based Interactive Modulation for Real-World
Super-Resolution (MM-RealSR). Specifically, we propose an unsupervised
degradation estimation strategy to estimate the degradation level in real-world
scenarios. Instead of using known degradation levels as explicit supervision to
the interactive mechanism, we propose a metric learning strategy to map the
unquantifiable degradation levels in real-world scenarios to a metric space,
which is trained in an unsupervised manner. Moreover, we introduce an anchor
point strategy in the metric learning process to normalize the distribution of
metric space. Extensive experiments demonstrate that the proposed MM-RealSR
achieves excellent modulation and restoration performance in real-world
super-resolution. Codes are available at
."#
statistics#statistics#methodology#Bayesian clustering of multiple zero-inflated outcomes#Beatrice Franzolini, Andrea Cremaschi, Willem van den Boom, Maria De Iorio#"Several applications involving counts present a large proportion of zeros
(excess-of-zeros data). A popular model for such data is the Hurdle model,
which explicitly models the probability of a zero count, while assuming a
sampling distribution on the positive integers. We consider data from multiple
count processes. In this context, it is of interest to study the patterns of
counts and cluster the subjects accordingly. We introduce a novel Bayesian
nonparametric approach to cluster multiple, possibly related, zero-inflated
processes. We propose a joint model for zero-inflated counts, specifying a
Hurdle model for each process with a shifted Negative Binomial sampling
distribution. Conditionally on the model parameters, the different processes
are assumed independent, leading to a substantial reduction in the number of
parameters as compared to traditional multivariate approaches. The
subject-specific probabilities of zero-inflation and the parameters of the
sampling distribution are flexibly modelled via an enriched finite mixture with
random number of components. This induces a two-level clustering of the
subjects based on the zero/non-zero patterns (outer clustering) and on the
sampling distribution (inner clustering). Posterior inference is performed
through tailored MCMC schemes. We demonstrate the proposed approach on an
application involving the use of the messaging service WhatsApp."#
statistics#statistics#methodology#Tuning Parameter Selection for Penalized Estimation via R2#Julia Holter, Jonathan Stallrich#"The tuning parameter selection strategy for penalized estimation is crucial
to identify a model that is both interpretable and predictive. However, popular
strategies (e.g., minimizing average squared prediction error via
cross-validation) tend to select models with more predictors than necessary.
This paper proposes a simple, yet powerful cross-validation strategy based on
maximizing squared correlations between the observed and predicted values,
rather than minimizing squared error loss. The strategy can be applied to all
penalized least-squares estimators and we show that, under certain conditions,
the metric implicitly performs a bias adjustment. Specific attention is given
to the lasso estimator, in which our strategy is closely related to the relaxed
lasso estimator. We demonstrate our approach on a functional variable selection
problem to identify optimal placement of surface electromyogram sensors to
control a robotic hand prosthesis."#
statistics#statistics#methodology#Principal Amalgamation Analysis for Microbiome Data#Yan Li, Gen Li, Kun Chen#"In recent years microbiome studies have become increasingly prevalent and
large-scale. Through high-throughput sequencing technologies and
well-established analytical pipelines, relative abundance data of operational
taxonomic units and their associated taxonomic structures are routinely
produced. Since such data can be extremely sparse and high dimensional, there
is often a genuine need for dimension reduction to facilitate data
visualization and downstream statistical analysis. We propose Principal
Amalgamation Analysis (PAA), a novel amalgamation-based and taxonomy-guided
dimension reduction paradigm for microbiome data. Our approach aims to
aggregate the compositions into a smaller number of principal compositions,
guided by the available taxonomic structure, by minimizing a properly measured
loss of information. The choice of the loss function is flexible and can be
based on familiar diversity indices for preserving either within-sample or
between-sample diversity in the data. To enable scalable computation, we
develop a hierarchical PAA algorithm to trace the entire trajectory of
successive simple amalgamations. Visualization tools including dendrogram,
scree plot, and ordination plot are developed. The effectiveness of PAA is
demonstrated using gut microbiome data from a preterm infant study and an HIV
infection study."#
statistics#statistics#methodology#Shared Frailty Methods for Complex Survival Data: A Review of Recent Advances#Malka Gorfine, David M. Zucker#"Dependent survival data arise in many contexts. One context is clustered
survival data, where survival data are collected on clusters such as families
or medical centers. Dependent survival data also arise when multiple survival
times are recorded for each individual. Frailty models is one common approach
to handle such data. In frailty models, the dependence is expressed in terms of
a random effect, called the frailty. Frailty models have been used with both
Cox proportional hazards model and the accelerated failure time model. This
paper reviews recent developments in the area of frailty models in a variety of
settings. In each setting we provide a detailed model description, assumptions,
available estimation methods, and R packages."#22 pages, 1 figure, 2 tables
statistics#statistics#methodology#Private Hypothesis Testing for Social Sciences#Ajinkya K Mulay, Sean Lane, Erin Hennes#"While running any experiment, we often have to consider the statistical power
to ensure an effective study. Statistical power or power ensures that we can
observe an effect with high probability if such a true effect exists. However,
several studies lack the appropriate planning for determining the optimal
sample size to ensure adequate power. Thus, careful planning ensures that the
power remains high even under high measurement errors while keeping the type 1
error constrained. We study the impact of differential privacy on experiments
and theoretically analyze the change in sample size required due to the
Gaussian mechanisms. Further, we provide an empirical method to improve the
accuracy of private statistics with simple bootstrapping."#Under review at Theory and Practice of Differential Privacy (TPDP) 2022
statistics#statistics#methodology#Leveraging baseline covariates to analyze small cluster-randomized trials with a rare binary outcome#Angela Y. Zhu, Nandita Mitra, Karla Hemming, Michael O. Harhay, Fan Li#"Cluster-randomized trials (CRTs) involve randomizing entire groups of
participants to treatment arms, but are often comprised of a limited number of
available clusters. While covariate adjustment can account for chance
imbalances between treatment arms and increase statistical efficiency in
individually-randomized trials, analytical methods for covariate adjustment in
small CRTs have received little attention to date. In this paper, we
systematically investigate, through extensive simulations, the operating
characteristics of propensity score weighting and multivariable regression as
two covariate adjustment strategies for estimating the participant-average
causal effect in small CRTs with a rare binary outcome and identify scenarios
where each covariate adjustment strategy has a relative efficiency advantage
over the other to make practical recommendations. Beyond efficiency
considerations, we also examined the finite-sample performance of the sandwich
variance estimators associated with propensity score weighting and
multivariable regression for quantifying the uncertainty in estimating the
participant-average treatment effect. We found that the \citet{mancl2001} type
bias-corrected sandwich variance estimator tends to provide the closest to
nominal coverage for both propensity score weighting and multivariable
regression estimators, extending the existing recommendations for unadjusted
analysis of CRTs to accommodate covariate adjustment in small CRTs with a rare
binary outcome. To illustrate the practical consequences of these various
adjustment approaches, we reanalyzed a recent CRT testing a sedation protocol
in $31$ pediatric intensive care units."#
statistics#statistics#methodology#Demystifying Inferential Models: A Fiducial Perspective#Yifan Cui, Jan Hannig#"Inferential models have recently gained in popularity for valid uncertainty
quantification. In this paper, we investigate inferential models by exploring
relationships between inferential models, fiducial inference, and confidence
curves. In short, we argue that from a certain point of view, inferential
models can be viewed as fiducial distribution based confidence curves. We show
that all probabilistic uncertainty quantification of inferential models is
based on a collection of sets we name principled sets and principled
assertions."#
statistics#statistics#methodology#Modeling panels of extremes#Debbie J. Dupuis, Sebastian Engelke, Luca Trapin#"Extreme value applications commonly employ regression techniques to capture
cross-sectional heterogeneity or time-variation in the data. Estimation of the
parameters of an extreme value regression model is notoriously challenging due
to the small number of observations that are usually available in applications.
When repeated extreme measurements are collected on the same individuals, i.e.,
a panel of extremes is available, pooling the observations in groups can
improve the statistical inference. We study three data sets related to risk
assessment in finance, climate science, and hydrology. In all three cases, the
problem can be formulated as an extreme value panel regression model with a
latent group structure and group-specific parameters. We propose a new
algorithm that jointly assigns the individuals to the latent groups and
estimates the parameters of the regression model inside each group. Our method
efficiently recovers the underlying group structure without prior information,
and for the three data sets it provides improved return level estimates and
helps answer important domain-specific questions."#
statistics#statistics#methodology#Data-Driven Optimal Sensor Placement for High-Dimensional System Using Annealing Machine#Tomoki Inoue, Tsubasa Ikami, Yasuhiro Egami, Hiroki Nagai, Yasuo Naganuma, Koichi Kimura, Yu Matsuda#"We propose a novel method for solving optimal sensor placement problem for
high-dimensional system using an annealing machine. The sensor points are
calculated as a maximum clique problem of the graph, the edge weight of which
is determined by the proper orthogonal decomposition (POD) mode obtained from
data based on the fact that a high-dimensional system usually has a
low-dimensional representation. Since the maximum clique problem is equivalent
to the independent set problem of the complement graph, the independent set
problem is solved using Fujitsu Digital Annealer. As a demonstration of the
proposed method, the pressure distribution induced by the Kármán vortex
street behind a square cylinder is reconstructed based on the pressure data at
the calculated sensor points. The pressure distribution is measured by
pressure-sensitive paint (PSP) technique, which is an optical flow diagnose
method. The root mean square errors (RMSEs) between the pressure measured by
pressure transducer and the reconstructed pressures (calculated from the
proposed method and an existing greedy method) at the same place are compared.
As the result, the similar RMSE is achieved by the proposed method using
approximately 1/5 number of sensor points obtained by the existing method. This
method is of great importance as a novel approach for optimal sensor placement
problem and a new engineering application of an annealing machine."#
statistics#statistics#methodology#Sequential Linear Discriminant Analysis in High Dimensions Using Individual Discriminant Functions#Seungchul Baek#"High dimensional classification has been highlighted for last two decades and
much research has been conducted in order to circumvent challenges encountered
in high dimensions. While existing methods have focused mainly on developing
classification rules assuming independence of covariates or using
regularization on the sample covariance matrix or the sample mean vector or
among others, we propose a novel approach that employs the ""discriminatory
power"" of each covariate, selects a set of important variables yielding the
lowest misclassification rate empirically, and constructs the optimal linear
classifier with selected variables. We carry out simulation studies and analyze
real data sets to illustrate the performance of our proposed classifier by
comparing it with existing classifiers."#22 pages, 3 figures
statistics#statistics#methodology#An Accelerated Failure Time Regression Model for Illness-Death Data: A Frailty Approach#Lea Kats, Malka Gorfine#"This work presents a new model and estimation procedure for the illness-death
survival data where the hazard functions follow accelerated failure time (AFT)
models. A shared frailty variate induces positive dependence among failure
times of a subject for handling the unobserved dependency between the
non-terminal and the terminal failure times given the observed covariates.
Semi-parametric maximum likelihood estimation procedure is developed via a
kernel smoothed-aided EM algorithm, and variances are estimated by weighted
bootstrap. The model is presented in the context of existing frailty-based
illness-death models, emphasizing the contribution of the current work. The
breast cancer data of the Rotterdam tumor bank are analyzed using the proposed
and existing illness-death models. The results are contrasted and evaluated
based on a new graphical goodness-of-fit procedure. Simulation results and data
analysis nicely demonstrate the practical utility of the shared frailty variate
with the AFT regression model under the illness-death framework."#
statistics#statistics#methodology#Inference of multivariate exponential Hawkesprocesses with inhibition and application toneuronal activity#Anna Bonnet, Miguel Martinez Herrera, Maxime Sangnier#"The Hawkes process is a multivariate past-dependent point process used to
model the relationship of event occurrences between different phenomena.
Although the Hawkes process was originally introduced to describe excitation
interactions, which means that one event increases the chances of another
occurring, there has been a growing interest in modeling the opposite effect,
known as inhibition. In this paper, we propose a maximum likelihood approach to
estimate the interaction functions of a multivariate Hawkes process that can
account for both exciting and inhibiting effects. To the best of our knowledge,
this is the first exact inference procedure designed for such a general setting
in the frequentist framework. Our method includes a thresholding step in order
to recover the support of interactions and therefore to infer the connectivity
graph. A benefit of our method is to provide an explicit computation of the
log-likelihood, which enables in addition to perform a goodness-of-fit test for
assessing the quality of estimations. We compare our method to classical
approaches, which were developed in the linear framework and are not
specifically designed for handling inhibiting effects. We show that the
proposed estimator performs better on synthetic data than alternative
approaches. We also illustrate the application of our procedure to a neuronal
activity dataset, which highlights the presence of both exciting and inhibiting
effects between neurons."#
statistics#statistics#methodology#The saturated pairwise interaction Gibbs point process as a joint species distribution model#Ian Flint, Nick Golding, Peter Vesk, Yan Wang, Aihua Xia#"In an effort to effectively model observed patterns in the spatial
configuration of individuals of multiple species in nature, we introduce the
saturated pairwise interaction Gibbs point process. Its main strength lies in
its ability to model both attraction and repulsion within and between species,
over different scales. As such, it is particularly well-suited to the study of
associations in complex ecosystems. Based on the existing literature, we
provide an easy to implement fitting procedure as well as a technique to make
inference for the model parameters. We also prove that under certain hypotheses
the point process is locally stable, which allows us to use the well-known
`coupling from the past' algorithm to draw samples from the model. Different
numerical experiments show the robustness of the model. We study three
different ecological datasets, demonstrating in each one that our model helps
disentangle competing ecological effects on species' distribution."#
statistics#statistics#methodology#A Comparative Tutorial of Bayesian Sequential Design and Reinforcement Learning#Mauricio Tec, Yunshan Duan, Peter Müller#"Reinforcement Learning (RL) is a computational approach to reward-driven
learning in sequential decision problems. It implements the discovery of
optimal actions by learning from an agent interacting with an environment
rather than from supervised data. We contrast and compare RL with traditional
sequential design, focusing on simulation-based Bayesian sequential design
(BSD). Recently, there has been an increasing interest in RL techniques for
healthcare applications. We introduce two related applications as motivating
examples. In both applications, the sequential nature of the decisions is
restricted to sequential stopping. Rather than a comprehensive survey, the
focus of the discussion is on solutions using standard tools for these two
relatively simple sequential stopping problems. Both problems are inspired by
adaptive clinical trial design. We use examples to explain the terminology and
mathematical background that underlie each framework and map one to the other.
The implementations and results illustrate the many similarities between RL and
BSD. The results motivate the discussion of the potential strengths and
limitations of each approach."#5 figures
statistics#statistics#methodology#Forecast combinations: an over 50-year review#Xiaoqian Wang, Rob J Hyndman, Feng Li, Yanfei Kang#"Forecast combinations have flourished remarkably in the forecasting community
and, in recent years, have become part of the mainstream of forecasting
research and activities. Combining multiple forecasts produced from the single
(target) series is now widely used to improve accuracy through the integration
of information gleaned from different sources, thereby mitigating the risk of
identifying a single ""best"" forecast. Combination schemes have evolved from
simple combination methods without estimation, to sophisticated methods
involving time-varying weights, nonlinear combinations, correlations among
components, and cross-learning. They include combining point forecasts, and
combining probabilistic forecasts. This paper provides an up-to-date review of
the extensive literature on forecast combinations, together with reference to
available open-source software implementations. We discuss the potential and
limitations of various methods and highlight how these ideas have developed
over time. Some important issues concerning the utility of forecast
combinations are also surveyed. Finally, we conclude with current research gaps
and potential insights for future research."#
statistics#statistics#methodology#On Exact Feature Screening in Ultrahigh-dimensional Binary Classification#Sarbojit Roy, Soham Sarkar, Subhajit Dutta, Anil K. Ghosh#"In this article, we propose a new model-free feature screening method based
on energy distances for ultrahigh-dimensional binary classification problems.
Unlike existing methods, the cut-off involved in our procedure is data
adaptive. With a high probability, the screened set retains only features after
discarding all the noise variables. The proposed screening method is then
extended to identify pairs of variables that are marginally undetectable, but
have differences in their joint distributions. Finally, we build a classifier
which maintains coherence between the proposed feature selection criteria and
discrimination method, and also establish its risk consistency. An extensive
numerical study with simulated data sets and real benchmark data sets show
clear and convincing advantages of our classifier over what currently exists in
the literature."#Paper: 26 pages, Supplementary: 31 pages
statistics#statistics#methodology#Enhanced Change-Point Detection in Functional Means#Shuhao Jiao, Ngai-Hang Chan, Chun-Yip Yau#"A new dimension reduction methodology for change-point detection in
functional means is developed in this paper. The major advantage and novelty of
the proposed method is its efficiency in selecting basis functions that capture
the change, or jump, of functional means, leading to higher detection power,
especially when the functions cannot be sufficiently explained by a small
number of basis functions or are contaminated by random noises. The throughly
developed theoretical results demonstrate that, even when the change shrinks to
zero, the proposed approach can still detect the change asymptotically almost
surely. The numerical simulation studies justify the superiority of the
proposed approach to the method based on functional principal components and
the fully functional approach without dimension reduction. An application to
annual humidity trajectories was also included to illustrate the practical
superiority of the developed approach."#
statistics#statistics#methodology#On a wider class of prior distributions for graphical models#Abhinav Natarajan, Willem van den Boom, Kristoforus Bryant Odang, Maria De Iorio#"Gaussian graphical models are useful tools for conditional independence
structure inference of multivariate random variables. Unfortunately, Bayesian
inference of latent graph structures is challenging due to exponential growth
of $\mathcal{G}_n$, the set of all graphs in $n$ vertices. One approach that
has been proposed to tackle this problem is to limit search to subsets of
$\mathcal{G}_n$. In this paper, we study subsets that are vector subspaces with
the cycle space $\mathcal{C}_n$ as main example. We propose a novel prior on
$\mathcal{C}_n$ based on linear combinations of cycle basis elements and
present its theoretical properties. Using this prior, we implemented a Markov
chain Monte Carlo algorithm and show that (i) posterior edge inclusion
estimates compared to the standard technique are comparable despite searching a
smaller graph space and (ii) the vector space perspective enables
straightforward MCMC algorithms."#31 pages, 6 figures
statistics#statistics#methodology#Efficient and flexible estimation of natural mediation effects under intermediate confounding and monotonicity constraints#Kara E. Rudolph, Ivan Diaz#"Natural direct and indirect effects are mediational estimands that decompose
the average treatment effect and describe how outcomes would be affected by
contrasting levels of a treatment through changes induced in mediator values
(in the case of the indirect effect) or not through induced changes in the
mediator values (in the case of the direct effect). Natural direct and indirect
effects are not generally point-identifiable in the presence of a
treatment-induced confounder, however they may still be identified if one is
willing to assume monotonicity between a treatment and the treatment-induced
confounder. We argue that this assumption may be reasonable in the relatively
common encouragement-design trial setting where intervention is randomized
treatment assignment and the treatment-induced confounder is whether or not
treatment was actually taken/adhered to. We develop efficiency theory for the
natural direct and indirect effects under this monotonicity assumption, and use
it to propose a nonparametric, multiply robust estimator. We demonstrate the
finite sample properties of this estimator using a simulation study, and apply
it to data from the Moving to Opportunity Study to estimate the natural direct
and indirect effects of being randomly assigned to receive a Section 8 housing
voucher -- the most common form of federal housing assistance -- on risk
developing any mood or externalizing disorder among adolescent boys, possibly
operating through various school and community characteristics."#
statistics#statistics#methodology#Bayesian Capture-Recapture Models that Facilitate Recursive Computing#Mevin B Hooten, Michael R Schwob, Devin S Johnson, Jacob S. Ivan#"Ecologists increasingly rely on Bayesian capture-recapture models to estimate
abundance of wildlife populations. Capture-recapture models account for
imperfect detectability in individual-level presence data. A variety of
approaches have been used to implement such models, including integrated
likelihood, parameter-expanded data augmentation, and combinations of those.
Recently proposed conditional specifications have improved the stability of
algorithms for fitting capture-recapture models. We arrive at similar
conditional specifications of capture-recapture models by considering recursive
implementation strategies that facilitate fitting models to large data sets.
Our approach enjoys the same computational stability but also allows us to fit
the desired model in stages and leverage parallel computing resources. Our
model specification includes a component for the capture history of detected
individuals and another component for the sample size which is random before
observed. We demonstrate this approach using three examples including
simulation and two data sets resulting from capture-recapture studies of
different species."#
statistics#statistics#methodology#Hypothesis Tests with Functional Data for Surface Quality Change Detection in Surface Finishing Processes#Shilan Jin, Rui Tuo, Akash Tiwari, Satish Bukkapatnam, Chantel Aracne-Ruddle, Ariel Lighty, Haley Hamza, Yu Ding#"This work is concerned with providing a principled decision process for
stopping or tool-changing in a surface finishing process. The decision process
is supposed to work for products of non-flat geometry. The solution is based on
conducting hypothesis testing on the bearing area curves from two consecutive
stages of a surface finishing process. In each stage, the bearing area curves,
which are in fact the nonparametric quantile curves representing the surface
roughness, are extracted from surface profile measurements at a number of
sampling locations on the surface of the products. The hypothesis test of these
curves informs the decision makers whether there is a change in surface quality
induced by the current finishing action. When such change is detected, the
current action is deemed effective and should thus continue, while when no
change is detected, the effectiveness of the current action is then called into
question, signaling possibly some change in the course of action. Application
of the hypothesis testing-based decision procedure to both spherical and flat
surfaces demonstrates the effectiveness and benefit of the proposed method and
confirms its geometry-agnostic nature."#33 pages, 12 figures
statistics#statistics#methodology#Towards better reconciling randomized controlled trial and observational study findings: Efficient algorithms for building representative matched samples with enhanced external validity#Bo Zhang#"Many recent efforts center on assessing the ability of real-world evidence
(RWE) generated from nonrandomized observational data to provide results that
are compatible with those from randomized controlled trials (RCTs). One
noticeable endeavor is the RCT DUPLICATE initiative (Franklin et al., 2020). To
better reconcile findings from observational and trial data, it is desirable to
eliminate differences between the RCT and corresponding observational study
populations. We outline an efficient, network-flow-based statistical matching
algorithm that designs well-matched pairs from observational data that mimic
the covariates' distribution of a target population, e.g., the RCT study
population or a population of scientific interest. We demonstrate the
usefulness of the method by revisiting the inconsistency regarding a
cardioprotective effect of the hormone replacement therapy (HRT) in the Women's
Health Initiative (WHI) clinical trial and corresponding observational study.
We found that the discrepancy between the trial and observational study
persisted in a design that adjusted for study populations' cardiovascular risk
profile, but seemed to disappear in a study design that further adjusted for
the HRT initiation age and previous estrogen-plus-progestin use. The proposed
method is integrated into the R package match2C."#
statistics#statistics#methodology#Addendum on the scoring of Gaussian directed acyclic graphical models#Jack Kuipers, Giusi Moffa, David Heckerman#"We provide a correction to the expression for scoring Gaussian directed
acyclic graphical models derived in Geiger and Heckerman [Ann. Statist. 30
(2002) 1414-1440] and discuss how to evaluate the score efficiently."#Published in at  the Annals of Statistics () by the Institute of Mathematical Statistics (). Typo in definition of R and one sentence corrected
statistics#statistics#methodology#Partition MCMC for inference on acyclic digraphs#Jack Kuipers, Giusi Moffa#"Acyclic digraphs are the underlying representation of Bayesian networks, a
widely used class of probabilistic graphical models. Learning the underlying
graph from data is a way of gaining insights about the structural properties of
a domain. Structure learning forms one of the inference challenges of
statistical graphical models.
MCMC methods, notably structure MCMC, to sample graphs from the posterior
distribution given the data are probably the only viable option for Bayesian
model averaging. Score modularity and restrictions on the number of parents of
each node allow the graphs to be grouped into larger collections, which can be
scored as a whole to improve the chain's convergence. Current examples of
algorithms taking advantage of grouping are the biased order MCMC, which acts
on the alternative space of permuted triangular matrices, and non ergodic edge
reversal moves.
Here we propose a novel algorithm, which employs the underlying combinatorial
structure of DAGs to define a new grouping. As a result convergence is improved
compared to structure MCMC, while still retaining the property of producing an
unbiased sample. Finally the method can be combined with edge reversal moves to
improve the sampler further."#Revised version. 34 pages, 16 figures. R code available at
statistics#statistics#methodology#Minimum Cost Intervention Design for Causal Effect Identification#Sina Akbari, Jalal Etesami, Negar Kiyavash#"Pearl's do calculus is a complete axiomatic approach to learn the
identifiable causal effects from observational data. When such an effect is not
identifiable, it is necessary to perform a collection of often costly
interventions in the system to learn the causal effect. In this work, we
consider the problem of designing the collection of interventions with the
minimum cost to identify the desired effect. First, we prove that this problem
is NP-hard, and subsequently propose an algorithm that can either find the
optimal solution or a logarithmic-factor approximation of it. This is done by
establishing a connection between our problem and the minimum hitting set
problem. Additionally, we propose several polynomial-time heuristic algorithms
to tackle the computational complexity of the problem. Although these
algorithms could potentially stumble on sub-optimal solutions, our simulations
show that they achieve small regrets on random graphs."#31 pages, 10 figures, ICML2022
statistics#statistics#methodology#Choosing Exogeneity Assumptions in Potential Outcome Models#Matthew A. Masten, Alexandre Poirier#"There are many kinds of exogeneity assumptions. How should researchers choose
among them? When exogeneity is imposed on an unobservable like a potential
outcome, we argue that the form of exogeneity should be chosen based on the
kind of selection on unobservables it allows. Consequently, researchers can
assess the plausibility of any exogeneity assumption by studying the
distributions of treatment given the unobservables that are consistent with
that assumption. We use this approach to study two common exogeneity
assumptions: quantile and mean independence. We show that both assumptions
require a kind of non-monotonic relationship between treatment and the
potential outcomes. We discuss how to assess the plausibility of this kind of
treatment selection. We also show how to define a new and weaker version of
quantile independence that allows for monotonic treatment selection. We then
show the implications of the choice of exogeneity assumption for
identification. We apply these results in an empirical illustration of the
effect of child soldiering on wages."#"This paper supersedes our previous paper titled ""Interpreting Quantile Independence"" ()"
=======
computer science#computing research repository#computer vision and pattern recognition#Proto2Proto: Can you recognize the car, the way I do?#Monish Keswani, Sriranjani Ramakrishnan, Nishant Reddy, Vineeth N Balasubramanian#"Prototypical methods have recently gained a lot of attention due to their
intrinsic interpretable nature, which is obtained through the prototypes. With
growing use cases of model reuse and distillation, there is a need to also
study transfer of interpretability from one model to another. We present
Proto2Proto, a novel method to transfer interpretability of one prototypical
part network to another via knowledge distillation. Our approach aims to add
interpretability to the ""dark"" knowledge transferred from the teacher to the
shallower student model. We propose two novel losses: ""Global Explanation"" loss
and ""Patch-Prototype Correspondence"" loss to facilitate such a transfer. Global
Explanation loss forces the student prototypes to be close to teacher
prototypes, and Patch-Prototype Correspondence loss enforces the local
representations of the student to be similar to that of the teacher. Further,
we propose three novel metrics to evaluate the student's proximity to the
teacher as measures of interpretability transfer in our settings. We
qualitatively and quantitatively demonstrate the effectiveness of our method on
CUB-200-2011 and Stanford Cars datasets. Our experiments show that the proposed
method indeed achieves interpretability transfer from teacher to student while
simultaneously exhibiting competitive performance."#
computer science#computing research repository#computer vision and pattern recognition#PedRecNet: Multi-task deep neural network for full 3D human pose and  orientation estimation#Dennis Burgermeister, Cristóbal Curio#"We present a multitask network that supports various deep neural network
based pedestrian detection functions. Besides 2D and 3D human pose, it also
supports body and head orientation estimation based on full body bounding box
input. This eliminates the need for explicit face recognition. We show that the
performance of 3D human pose estimation and orientation estimation is
comparable to the state-of-the-art. Since very few data sets exist for 3D human
pose and in particular body and head orientation estimation based on full body
data, we further show the benefit of particular simulation data to train the
network. The network architecture is relatively simple, yet powerful, and
easily adaptable for further research and applications."#
computer science#computing research repository#computer vision and pattern recognition#Rethinking Multi-Modal Alignment in Video Question Answering from  Feature and Sample Perspectives#Shaoning Xiao, Long Chen, Kaifeng Gao, Zhao Wang, Yi Yang, Jun Xiao#"Reasoning about causal and temporal event relations in videos is a new
destination of Video Question Answering (VideoQA).The major stumbling block to
achieve this purpose is the semantic gap between language and video since they
are at different levels of abstraction. Existing efforts mainly focus on
designing sophisticated architectures while utilizing frame- or object-level
visual representations. In this paper, we reconsider the multi-modal alignment
problem in VideoQA from feature and sample perspectives to achieve better
performance. From the view of feature,we break down the video into trajectories
and first leverage trajectory feature in VideoQA to enhance the alignment
between two modalities. Moreover, we adopt a heterogeneous graph architecture
and design a hierarchical framework to align both trajectory-level and
frame-level visual feature with language feature. In addition, we found that
VideoQA models are largely dependent on language priors and always neglect
visual-language interactions. Thus, two effective yet portable training
augmentation strategies are designed to strengthen the cross-modal
correspondence ability of our model from the view of sample. Extensive results
show that our method outperforms all the state-of-the-art models on the
challenging NExT-QA benchmark, which demonstrates the effectiveness of the
proposed method."#
computer science#computing research repository#computer vision and pattern recognition#Joint-Modal Label Denoising for Weakly-Supervised Audio-Visual Video  Parsing#Haoyue Cheng, Zhaoyang Liu, Hang Zhou, Chen Qian, Wayne Wu, Limin Wang#"This paper focuses on the weakly-supervised audio-visual video parsing task,
which aims to recognize all events belonging to each modality and localize
their temporal boundaries. This task is challenging because only overall labels
indicating the video events are provided for training. However, an event might
be labeled but not appear in one of the modalities, which results in a
modality-specific noisy label problem. Motivated by two observations that
networks tend to learn clean samples first and that a labeled event would
appear in at least one modality, we propose a training strategy to identify and
remove modality-specific noisy labels dynamically. Specifically, we sort the
losses of all instances within a mini-batch individually in each modality, then
select noisy samples according to relationships between intra-modal and
inter-modal losses. Besides, we also propose a simple but valid noise ratio
estimation method by calculating the proportion of instances whose confidence
is below a preset threshold. Our method makes large improvements over the
previous state of the arts (e.g., from 60.0% to 63.8% in segment-level visual
metric), which demonstrates the effectiveness of our approach."#
computer science#computing research repository#computer vision and pattern recognition#Graph-DETR3D: Rethinking Overlapping Regions for Multi-View 3D Object  Detection#Zehui Chen, Zhenyu Li, Shiquan Zhang, Liangji Fang, Qinhong Jiang, Feng Zhao#"3D object detection from multiple image views is a fundamental and
challenging task for visual scene understanding. Due to its low cost and high
efficiency, multi-view 3D object detection has demonstrated promising
application prospects. However, accurately detecting objects through
perspective views in the 3D space is extremely difficult due to the lack of
depth information. Recently, DETR3D introduces a novel 3D-2D query paradigm in
aggregating multi-view images for 3D object detection and achieves
state-of-the-art performance. In this paper, with intensive pilot experiments,
we quantify the objects located at different regions and find that the
""truncated instances"" (i.e., at the border regions of each image) are the main
bottleneck hindering the performance of DETR3D. Although it merges multiple
features from two adjacent views in the overlapping regions, DETR3D still
suffers from insufficient feature aggregation, thus missing the chance to fully
boost the detection performance. In an effort to tackle the problem, we propose
Graph-DETR3D to automatically aggregate multi-view imagery information through
graph structure learning (GSL). It constructs a dynamic 3D graph between each
object query and 2D feature maps to enhance the object representations,
especially at the border regions. Besides, Graph-DETR3D benefits from a novel
depth-invariant multi-scale training strategy, which maintains the visual depth
consistency by simultaneously scaling the image size and the object depth.
Extensive experiments on the nuScenes dataset demonstrate the effectiveness and
efficiency of our Graph-DETR3D. Notably, our best model achieves 49.5 NDS on
the nuScenes test leaderboard, achieving new state-of-the-art in comparison
with various published image-view 3D object detectors."#
computer science#computing research repository#computer vision and pattern recognition#Combining Visual Saliency Methods and Sparse Keypoint Annotations to  Providently Detect Vehicles at Night#Lukas Ewecker, Lars Ohnemus, Robin Schwager, Stefan Roos, Sascha Saralajew#"Provident detection of other road users at night has the potential for
increasing road safety. For this purpose, humans intuitively use visual cues,
such as light cones and light reflections emitted by other road users to be
able to react to oncoming traffic at an early stage. This behavior can be
imitated by computer vision methods by predicting the appearance of vehicles
based on emitted light reflections caused by the vehicle's headlights. Since
current object detection algorithms are mainly based on detecting directly
visible objects annotated via bounding boxes, the detection and annotation of
light reflections without sharp boundaries is challenging. For this reason, the
extensive open-source dataset PVDN (Provident Vehicle Detection at Night) was
published, which includes traffic scenarios at night with light reflections
annotated via keypoints. In this paper, we explore the potential of
saliency-based approaches to create different object representations based on
the visual saliency and sparse keypoint annotations of the PVDN dataset. For
that, we extend the general idea of Boolean map saliency towards a
context-aware approach by taking into consideration sparse keypoint annotations
by humans. We show that this approach allows for an automated derivation of
different object representations, such as binary maps or bounding boxes so that
detection models can be trained on different annotation variants and the
problem of providently detecting vehicles at night can be tackled from
different perspectives. With that, we provide further powerful tools and
methods to study the problem of detecting vehicles at night before they are
actually visible."#
computer science#computing research repository#computer vision and pattern recognition#Goal-driven Self-Attentive Recurrent Networks for Trajectory Prediction#Luigi Filippo Chiara, Pasquale Coscia, Sourav Das, Simone Calderara, Rita Cucchiara, Lamberto Ballan#"Human trajectory forecasting is a key component of autonomous vehicles,
social-aware robots and advanced video-surveillance applications. This
challenging task typically requires knowledge about past motion, the
environment and likely destination areas. In this context, multi-modality is a
fundamental aspect and its effective modeling can be beneficial to any
architecture. Inferring accurate trajectories is nevertheless challenging, due
to the inherently uncertain nature of the future. To overcome these
difficulties, recent models use different inputs and propose to model human
intentions using complex fusion mechanisms. In this respect, we propose a
lightweight attention-based recurrent backbone that acts solely on past
observed positions. Although this backbone already provides promising results,
we demonstrate that its prediction accuracy can be improved considerably when
combined with a scene-aware goal-estimation module. To this end, we employ a
common goal module, based on a U-Net architecture, which additionally extracts
semantic information to predict scene-compliant destinations. We conduct
extensive experiments on publicly-available datasets (i.e. SDD, inD, ETH/UCY)
and show that our approach performs on par with state-of-the-art techniques
while reducing model complexity."#
computer science#computing research repository#computer vision and pattern recognition#Unsupervised Domain Adaptation for Monocular 3D Object Detection via  Self-Training#Zhenyu Li, Zehui Chen, Ang Li, Liangji Fang, Qinhong Jiang, Xianming Liu, Junjun Jiang#"Monocular 3D object detection (Mono3D) has achieved unprecedented success
with the advent of deep learning techniques and emerging large-scale autonomous
driving datasets. However, drastic performance degradation remains an
unwell-studied challenge for practical cross-domain deployment as the lack of
labels on the target domain. In this paper, we first comprehensively
investigate the significant underlying factor of the domain gap in Mono3D,
where the critical observation is a depth-shift issue caused by the geometric
misalignment of domains. Then, we propose STMono3D, a new self-teaching
framework for unsupervised domain adaptation on Mono3D. To mitigate the
depth-shift, we introduce the geometry-aligned multi-scale training strategy to
disentangle the camera parameters and guarantee the geometry consistency of
domains. Based on this, we develop a teacher-student paradigm to generate
adaptive pseudo labels on the target domain. Benefiting from the end-to-end
framework that provides richer information of the pseudo labels, we propose the
quality-aware supervision strategy to take instance-level pseudo confidences
into account and improve the effectiveness of the target-domain training
process. Moreover, the positive focusing training strategy and dynamic
threshold are proposed to handle tremendous FN and FP pseudo samples. STMono3D
achieves remarkable performance on all evaluated datasets and even surpasses
fully supervised results on the KITTI 3D object detection dataset. To the best
of our knowledge, this is the first study to explore effective UDA methods for
Mono3D."#
computer science#computing research repository#computer vision and pattern recognition#Multi-Layer Modeling of Dense Vegetation from Aerial LiDAR Scans#Ekaterina Kalinicheva, Loic Landrieu, Clément Mallet, Nesrine Chehata#"The analysis of the multi-layer structure of wild forests is an important
challenge of automated large-scale forestry. While modern aerial LiDARs offer
geometric information across all vegetation layers, most datasets and methods
focus only on the segmentation and reconstruction of the top of canopy. We
release WildForest3D, which consists of 29 study plots and over 2000 individual
trees across 47 000m2 with dense 3D annotation, along with occupancy and height
maps for 3 vegetation layers: ground vegetation, understory, and overstory. We
propose a 3D deep network architecture predicting for the first time both 3D
point-wise labels and high-resolution layer occupancy rasters simultaneously.
This allows us to produce a precise estimation of the thickness of each
vegetation layer as well as the corresponding watertight meshes, therefore
meeting most forestry purposes. Both the dataset and the model are released in
open access:"#
computer science#computing research repository#computer vision and pattern recognition#A Simple Structure For Building A Robust Model#Xiao Tan, JingBo Gao, Ruolin Li#"As deep learning applications, especially programs of computer vision, are
increasingly deployed in our lives, we have to think more urgently about the
security of these applications.One effective way to improve the security of
deep learning models is to perform adversarial training, which allows the model
to be compatible with samples that are deliberately created for use in
attacking the model.Based on this, we propose a simple architecture to build a
model with a certain degree of robustness, which improves the robustness of the
trained network by adding an adversarial sample detection network for
cooperative training.At the same time, we design a new data sampling strategy
that incorporates multiple existing attacks, allowing the model to adapt to
many different adversarial attacks with a single training.We conducted some
experiments to test the effectiveness of this design based on Cifar10 dataset,
and the results indicate that it has some degree of positive effect on the
robustness of the model.Our code could be found at"#
computer science#computing research repository#computer vision and pattern recognition#Loss-based Sequential Learning for Active Domain Adaptation#Kyeongtak Han, Youngeun Kim, Dongyoon Han, Sungeun Hong#"Active domain adaptation (ADA) studies have mainly addressed query selection
while following existing domain adaptation strategies. However, we argue that
it is critical to consider not only query selection criteria but also domain
adaptation strategies designed for ADA scenarios. This paper introduces
sequential learning considering both domain type (source/target) or labelness
(labeled/unlabeled). We first train our model only on labeled target samples
obtained by loss-based query selection. When loss-based query selection is
applied under domain shift, unuseful high-loss samples gradually increase, and
the labeled-sample diversity becomes low. To solve these, we fully utilize
pseudo labels of the unlabeled target domain by leveraging loss prediction. We
further encourage pseudo labels to have low self-entropy and diverse class
distributions. Our model significantly outperforms previous methods as well as
baseline models in various benchmark datasets."#
computer science#computing research repository#computer vision and pattern recognition#Multi-Head Distillation for Continual Unsupervised Domain Adaptation in  Semantic Segmentation#Antoine Saporta, Arthur Douillard, Tuan-Hung Vu, Patrick Pérez, Matthieu Cord#"Unsupervised Domain Adaptation (UDA) is a transfer learning task which aims
at training on an unlabeled target domain by leveraging a labeled source
domain. Beyond the traditional scope of UDA with a single source domain and a
single target domain, real-world perception systems face a variety of scenarios
to handle, from varying lighting conditions to many cities around the world. In
this context, UDAs with several domains increase the challenges with the
addition of distribution shifts within the different target domains. This work
focuses on a novel framework for learning UDA, continuous UDA, in which models
operate on multiple target domains discovered sequentially, without access to
previous target domains. We propose MuHDi, for Multi-Head Distillation, a
method that solves the catastrophic forgetting problem, inherent in continual
learning tasks. MuHDi performs distillation at multiple levels from the
previous model as well as an auxiliary target-specialist segmentation head. We
report both extensive ablation and experiments on challenging multi-target UDA
semantic segmentation benchmarks to validate the proposed learning scheme and
architecture."#
computer science#computing research repository#computer vision and pattern recognition#Hybrid ISTA: Unfolding ISTA With Convergence Guarantees Using Free-Form  Deep Neural Networks#Ziyang Zheng, Wenrui Dai, Duoduo Xue, Chenglin Li, Junni Zou, Hongkai Xiong#"It is promising to solve linear inverse problems by unfolding iterative
algorithms (e.g., iterative shrinkage thresholding algorithm (ISTA)) as deep
neural networks (DNNs) with learnable parameters. However, existing ISTA-based
unfolded algorithms restrict the network architectures for iterative updates
with the partial weight coupling structure to guarantee convergence. In this
paper, we propose hybrid ISTA to unfold ISTA with both pre-computed and learned
parameters by incorporating free-form DNNs (i.e., DNNs with arbitrary feasible
and reasonable network architectures), while ensuring theoretical convergence.
We first develop HCISTA to improve the efficiency and flexibility of classical
ISTA (with pre-computed parameters) without compromising the convergence rate
in theory. Furthermore, the DNN-based hybrid algorithm is generalized to
popular variants of learned ISTA, dubbed HLISTA, to enable a free architecture
of learned parameters with a guarantee of linear convergence. To our best
knowledge, this paper is the first to provide a convergence-provable framework
that enables free-form DNNs in ISTA-based unfolded algorithms. This framework
is general to endow arbitrary DNNs for solving linear inverse problems with
convergence guarantees. Extensive experiments demonstrate that hybrid ISTA can
reduce the reconstruction error with an improved convergence rate in the tasks
of sparse recovery and compressive sensing."#
computer science#computing research repository#computer vision and pattern recognition#Estimation of Reliable Proposal Quality for Temporal Action Detection#Junshan Hu, Chaoxu guo, Liansheng Zhuang, Biao Wang, Tiezheng Ge, Yuning Jiang, Houqiang Li#"Temporal action detection (TAD) aims to locate and recognize the actions in
an untrimmed video. Anchor-free methods have made remarkable progress which
mainly formulate TAD into two tasks: classification and localization using two
separate branches. This paper reveals the temporal misalignment between the two
tasks hindering further progress. To address this, we propose a new method that
gives insights into moment and region perspectives simultaneously to align the
two tasks by acquiring reliable proposal quality. For the moment perspective,
Boundary Evaluate Module (BEM) is designed which focuses on local appearance
and motion evolvement to estimate boundary quality and adopts a multi-scale
manner to deal with varied action durations. For the region perspective, we
introduce Region Evaluate Module (REM) which uses a new and efficient sampling
method for proposal feature representation containing more contextual
information compared with point feature to refine category score and proposal
boundary. The proposed Boundary Evaluate Module and Region Evaluate Module
(BREM) are generic, and they can be easily integrated with other anchor-free
TAD methods to achieve superior performance. In our experiments, BREM is
combined with two different frameworks and improves the performance on THUMOS14
by 3.6$\%$ and 1.0$\%$ respectively, reaching a new state-of-the-art (63.6$\%$
average $m$AP). Meanwhile, a competitive result of 36.2\% average $m$AP is
achieved on ActivityNet-1.3 with the consistent improvement of BREM."#
computer science#computing research repository#computer vision and pattern recognition#ClusterGNN: Cluster-based Coarse-to-Fine Graph Neural Network for  Efficient Feature Matching#Yan Shi, Jun-Xiong Cai, Yoli Shavit, Tai-Jiang Mu, Wensen Feng, Kai Zhang#"Graph Neural Networks (GNNs) with attention have been successfully applied
for learning visual feature matching. However, current methods learn with
complete graphs, resulting in a quadratic complexity in the number of features.
Motivated by a prior observation that self- and cross- attention matrices
converge to a sparse representation, we propose ClusterGNN, an attentional GNN
architecture which operates on clusters for learning the feature matching task.
Using a progressive clustering module we adaptively divide keypoints into
different subgraphs to reduce redundant connectivity, and employ a
coarse-to-fine paradigm for mitigating miss-classification within images. Our
approach yields a 59.7% reduction in runtime and 58.4% reduction in memory
consumption for dense detection, compared to current state-of-the-art GNN-based
matching, while achieving a competitive performance on various computer vision
tasks."#
computer science#computing research repository#computer vision and pattern recognition#Tac2Pose: Tactile Object Pose Estimation from the First Touch#Maria Bauza, Antonia Bronars, Alberto Rodriguez#"In this paper, we present Tac2Pose, an object-specific approach to tactile
pose estimation from the first touch for known objects. Given the object
geometry, we learn a tailored perception model in simulation that estimates a
probability distribution over possible object poses given a tactile
observation. To do so, we simulate the contact shapes that a dense set of
object poses would produce on the sensor. Then, given a new contact shape
obtained from the sensor, we match it against the pre-computed set using an
object-specific embedding learned using contrastive learning. We obtain contact
shapes from the sensor with an object-agnostic calibration step that maps RGB
tactile observations to binary contact shapes. This mapping, which can be
reused across object and sensor instances, is the only step trained with real
sensor data. This results in a perception model that localizes objects from the
first real tactile observation. Importantly, it produces pose distributions and
can incorporate additional pose constraints coming from other perception
systems, contacts, or priors.
We provide quantitative results for 20 objects. Tac2Pose provides high
accuracy pose estimations from distinctive tactile observations while
regressing meaningful pose distributions to account for those contact shapes
that could result from different object poses. We also test Tac2Pose on object
models reconstructed from a 3D scanner, to evaluate the robustness to
uncertainty in the object model. Finally, we demonstrate the advantages of
Tac2Pose compared with three baseline methods for tactile pose estimation:
directly regressing the object pose with a neural network, matching an observed
contact to a set of possible contacts using a standard classification neural
network, and direct pixel comparison of an observed contact with a set of
possible contacts.
Website:"#
computer science#computing research repository#computer vision and pattern recognition#Masked Image Modeling Advances 3D Medical Image Analysis#Zekai Chen, Devansh Agarwal, Kshitij Aggarwal, Wiem Safta, Mariann Micsinai Balan, Venkat Sethuraman, Kevin Brown#"Recently, masked image modeling (MIM) has gained considerable attention due
to its capacity to learn from vast amounts of unlabeled data and has been
demonstrated to be effective on a wide variety of vision tasks involving
natural images. Meanwhile, the potential of self-supervised learning in
modeling 3D medical images is anticipated to be immense due to the high
quantities of unlabeled images, and the expense and difficulty of quality
labels. However, MIM's applicability to medical images remains uncertain. In
this paper, we demonstrate that masked image modeling approaches can also
advance 3D medical images analysis in addition to natural images. We study how
masked image modeling strategies leverage performance from the viewpoints of 3D
medical image segmentation as a representative downstream task: i) when
compared to naive contrastive learning, masked image modeling approaches
accelerate the convergence of supervised training even faster (1.40$\times$)
and ultimately produce a higher dice score; ii) predicting raw voxel values
with a high masking ratio and a relatively smaller patch size is non-trivial
self-supervised pretext-task for medical images modeling; iii) a lightweight
decoder or projection head design for reconstruction is powerful for masked
image modeling on 3D medical images which speeds up training and reduce cost;
iv) finally, we also investigate the effectiveness of MIM methods under
different practical scenarios where different image resolutions and labeled
data ratios are applied."#
computer science#computing research repository#computer vision and pattern recognition#Real-Time Neural Character Rendering with Pose-Guided Multiplane Images#Hao Ouyang, Bo Zhang, Pan Zhang, Hao Yang, Jiaolong Yang, Dong Chen, Qifeng Chen, Fang Wen#"We propose pose-guided multiplane image (MPI) synthesis which can render an
animatable character in real scenes with photorealistic quality. We use a
portable camera rig to capture the multi-view images along with the driving
signal for the moving subject. Our method generalizes the image-to-image
translation paradigm, which translates the human pose to a 3D scene
representation -- MPIs that can be rendered in free viewpoints, using the
multi-views captures as supervision. To fully cultivate the potential of MPI,
we propose depth-adaptive MPI which can be learned using variable exposure
images while being robust to inaccurate camera registration. Our method
demonstrates advantageous novel-view synthesis quality over the
state-of-the-art approaches for characters with challenging motions. Moreover,
the proposed method is generalizable to novel combinations of training poses
and can be explicitly controlled. Our method achieves such expressive and
animatable character rendering all in real time, serving as a promising
solution for practical applications."#
computer science#computing research repository#computer vision and pattern recognition#4DAC: Learning Attribute Compression for Dynamic Point Clouds#Guangchi Fang, Qingyong Hu, Yiling Xu, Yulan Guo#"With the development of the 3D data acquisition facilities, the increasing
scale of acquired 3D point clouds poses a challenge to the existing data
compression techniques. Although promising performance has been achieved in
static point cloud compression, it remains under-explored and challenging to
leverage temporal correlations within a point cloud sequence for effective
dynamic point cloud compression. In this paper, we study the attribute (e.g.,
color) compression of dynamic point clouds and present a learning-based
framework, termed 4DAC. To reduce temporal redundancy within data, we first
build the 3D motion estimation and motion compensation modules with deep neural
networks. Then, the attribute residuals produced by the motion compensation
component are encoded by the region adaptive hierarchical transform into
residual coefficients. In addition, we also propose a deep conditional entropy
model to estimate the probability distribution of the transformed coefficients,
by incorporating temporal context from consecutive point clouds and the motion
estimation/compensation modules. Finally, the data stream is losslessly entropy
coded with the predicted distribution. Extensive experiments on several public
datasets demonstrate the superior compression performance of the proposed
approach."#
computer science#computing research repository#computer vision and pattern recognition#Adversarial Attention for Human Motion Synthesis#Matthew Malek-Podjaski, Fani Deligianni#"Analysing human motions is a core topic of interest for many disciplines,
from Human-Computer Interaction, to entertainment, Virtual Reality and
healthcare. Deep learning has achieved impressive results in capturing human
pose in real-time. On the other hand, due to high inter-subject variability,
human motion analysis models often suffer from not being able to generalise to
data from unseen subjects due to very limited specialised datasets available in
fields such as healthcare. However, acquiring human motion datasets is highly
time-consuming, challenging, and expensive. Hence, human motion synthesis is a
crucial research problem within deep learning and computer vision. We present a
novel method for controllable human motion synthesis by applying
attention-based probabilistic deep adversarial models with end-to-end training.
We show that we can generate synthetic human motion over both short- and
long-time horizons through the use of adversarial attention. Furthermore, we
show that we can improve the classification performance of deep learning models
in cases where there is inadequate real data, by supplementing existing
datasets with synthetic motions."#
computer science#computing research repository#computer vision and pattern recognition#PVNAS: 3D Neural Architecture Search with Point-Voxel Convolution#Zhijian Liu, Haotian Tang, Shengyu Zhao, Kevin Shao, Song Han#"3D neural networks are widely used in real-world applications (e.g., AR/VR
headsets, self-driving cars). They are required to be fast and accurate;
however, limited hardware resources on edge devices make these requirements
rather challenging. Previous work processes 3D data using either voxel-based or
point-based neural networks, but both types of 3D models are not
hardware-efficient due to the large memory footprint and random memory access.
In this paper, we study 3D deep learning from the efficiency perspective. We
first systematically analyze the bottlenecks of previous 3D methods. We then
combine the best from point-based and voxel-based models together and propose a
novel hardware-efficient 3D primitive, Point-Voxel Convolution (PVConv). We
further enhance this primitive with the sparse convolution to make it more
effective in processing large (outdoor) scenes. Based on our designed 3D
primitive, we introduce 3D Neural Architecture Search (3D-NAS) to explore the
best 3D network architecture given a resource constraint. We evaluate our
proposed method on six representative benchmark datasets, achieving
state-of-the-art performance with 1.8-23.7x measured speedup. Furthermore, our
method has been deployed to the autonomous racing vehicle of MIT Driverless,
achieving larger detection range, higher accuracy and lower latency."#
computer science#computing research repository#computer vision and pattern recognition#Generalizable Neural Performer: Learning Robust Radiance Fields for  Human Novel View Synthesis#Wei Cheng, Su Xu, Jingtan Piao, Chen Qian, Wayne Wu, Kwan-Yee Lin, Hongsheng Li#"This work targets at using a general deep learning framework to synthesize
free-viewpoint images of arbitrary human performers, only requiring a sparse
number of camera views as inputs and skirting per-case fine-tuning. The large
variation of geometry and appearance, caused by articulated body poses, shapes
and clothing types, are the key bottlenecks of this task. To overcome these
challenges, we present a simple yet powerful framework, named Generalizable
Neural Performer (GNR), that learns a generalizable and robust neural body
representation over various geometry and appearance. Specifically, we compress
the light fields for novel view human rendering as conditional implicit neural
radiance fields from both geometry and appearance aspects. We first introduce
an Implicit Geometric Body Embedding strategy to enhance the robustness based
on both parametric 3D human body model and multi-view images hints. We further
propose a Screen-Space Occlusion-Aware Appearance Blending technique to
preserve the high-quality appearance, through interpolating source view
appearance to the radiance fields with a relax but approximate geometric
guidance.
To evaluate our method, we present our ongoing effort of constructing a
dataset with remarkable complexity and diversity. The dataset GeneBody-1.0,
includes over 360M frames of 370 subjects under multi-view cameras capturing,
performing a large variety of pose actions, along with diverse body shapes,
clothing, accessories and hairdos. Experiments on GeneBody-1.0 and ZJU-Mocap
show better robustness of our methods than recent state-of-the-art
generalizable methods among all cross-dataset, unseen subjects and unseen poses
settings. We also demonstrate the competitiveness of our model compared with
cutting-edge case-specific ones. Dataset, code and model will be made publicly
available."#
computer science#computing research repository#computer vision and pattern recognition#Zero-Shot Logit Adjustment#Dubing Chen, Yuming Shen, Haofeng Zhang, Philip H.S. Torr#"Semantic-descriptor-based Generalized Zero-Shot Learning (GZSL) poses
challenges in recognizing the novel classes in the test phase. The development
of generative models enables current GZSL techniques to probe further into the
semantic-visual link, culminating in a two-stage form that includes a generator
and a classifier. However, existing generation-based methods focus on enhancing
the generator's effect while neglecting the improvement of the classifier. In
this paper, we first conduct an analysis of two properties of the generated
pseudo unseen sample: bias and homogeneity. Then, we perform variational
Bayesian inference to back-derive the evaluation metrics, which reflects the
balance of the seen and unseen classes. As a consequence of our derivation, the
aforementioned two properties are incorporated into the classifier training as
seen-unseen priors via logit adjustment. The Zero-Shot Logit Adjustment further
puts semantic-based classifiers into effect in generation-based GZSL. Our
experiments demonstrate that the proposed technique achieves the state of the
art when combined with the basic generator, and it can improve various
generative zero-shot learning frameworks. Our codes are available on
\url{}."#
computer science#computing research repository#computer vision and pattern recognition#StyleGAN-Human: A Data-Centric Odyssey of Human Generation#Jianglin Fu, Shikai Li, Yuming Jiang, Kwan-Yee Lin, Chen Qian, Chen Change Loy, Wayne Wu, Ziwei Liu#"Unconditional human image generation is an important task in vision and
graphics, which enables various applications in the creative industry. Existing
studies in this field mainly focus on ""network engineering"" such as designing
new components and objective functions. This work takes a data-centric
perspective and investigates multiple critical aspects in ""data engineering"",
which we believe would complement the current practice. To facilitate a
comprehensive study, we collect and annotate a large-scale human image dataset
with over 230K samples capturing diverse poses and textures. Equipped with this
large dataset, we rigorously investigate three essential factors in data
engineering for StyleGAN-based human generation, namely data size, data
distribution, and data alignment. Extensive experiments reveal several valuable
observations w.r.t. these aspects: 1) Large-scale data, more than 40K images,
are needed to train a high-fidelity unconditional human generation model with
vanilla StyleGAN. 2) A balanced training set helps improve the generation
quality with rare face poses compared to the long-tailed counterpart, whereas
simply balancing the clothing texture distribution does not effectively bring
an improvement. 3) Human GAN models with body centers for alignment outperform
models trained using face centers or pelvis points as alignment anchors. In
addition, a model zoo and human editing applications are demonstrated to
facilitate future research in the community."#
computer science#computing research repository#computer vision and pattern recognition#Retrieval-Augmented Diffusion Models#Andreas Blattmann, Robin Rombach, Kaan Oktay, Björn Ommer#"Generative image synthesis with diffusion models has recently achieved
excellent visual quality in several tasks such as text-based or
class-conditional image synthesis. Much of this success is due to a dramatic
increase in the computational capacity invested in training these models. This
work presents an alternative approach: inspired by its successful application
in natural language processing, we propose to complement the diffusion model
with a retrieval-based approach and to introduce an explicit memory in the form
of an external database. During training, our diffusion model is trained with
similar visual features retrieved via CLIP and from the neighborhood of each
training instance. By leveraging CLIP's joint image-text embedding space, our
model achieves highly competitive performance on tasks for which it has not
been explicitly trained, such as class-conditional or text-image synthesis, and
can be conditioned on both text and image embeddings. Moreover, we can apply
our approach to unconditional generation, where it achieves state-of-the-art
performance. Our approach incurs low computational and memory overheads and is
easy to implement. We discuss its relationship to concurrent work and will
publish code and pretrained models soon."#
computer science#computing research repository#machine learning#Hate Me Not: Detecting Hate Inducing Memes in Code Switched Languages#Kshitij Rajput, Raghav Kapoor, Kaushal Rai, Preeti Kaur#"The rise in the number of social media users has led to an increase in the
hateful content posted online. In countries like India, where multiple
languages are spoken, these abhorrent posts are from an unusual blend of
code-switched languages. This hate speech is depicted with the help of images
to form ""Memes"" which create a long-lasting impact on the human mind. In this
paper, we take up the task of hate and offense detection from multimodal data,
i.e. images (Memes) that contain text in code-switched languages. We firstly
present a novel triply annotated Indian political Memes (IPM) dataset, which
comprises memes from various Indian political events that have taken place
post-independence and are classified into three distinct categories. We also
propose a binary-channelled CNN cum LSTM based model to process the images
using the CNN model and text using the LSTM model to get state-of-the-art
results for this task."#
computer science#computing research repository#machine learning#Towards Evaluating Adaptivity of Model-Based Reinforcement Learning  Methods#Yi Wan, Ali Rahimi-Kalahroudi, Janarthanan Rajendran, Ida Momennejad, Sarath Chandar, Harm van Seijen#"In recent years, a growing number of deep model-based reinforcement learning
(RL) methods have been introduced. The interest in deep model-based RL is not
surprising, given its many potential benefits, such as higher sample efficiency
and the potential for fast adaption to changes in the environment. However, we
demonstrate, using an improved version of the recently introduced Local Change
Adaptation (LoCA) setup, that well-known model-based methods such as PlaNet and
DreamerV2 perform poorly in their ability to adapt to local environmental
changes. Combined with prior work that made a similar observation about the
other popular model-based method, MuZero, a trend appears to emerge, suggesting
that current deep model-based methods have serious limitations. We dive deeper
into the causes of this poor performance, by identifying elements that hurt
adaptive behavior and linking these to underlying techniques frequently used in
deep model-based RL. We empirically validate these insights in the case of
linear function approximation by demonstrating that a modified version of
linear Dyna achieves effective adaptation to local changes. Furthermore, we
provide detailed insights into the challenges of building an adaptive nonlinear
model-based method, by experimenting with a nonlinear version of Dyna."#
computer science#computing research repository#machine learning#Deep Reinforcement Learning for Online Routing of Unmanned Aerial  Vehicles with Wireless Power Transfer#Kaiwen Li, Tao Zhang, Rui Wang, Ling Wang#"The unmanned aerial vehicle (UAV) plays an vital role in various applications
such as delivery, military mission, disaster rescue, communication, etc., due
to its flexibility and versatility. This paper proposes a deep reinforcement
learning method to solve the UAV online routing problem with wireless power
transfer, which can charge the UAV remotely without wires, thus extending the
capability of the battery-limited UAV. Our study considers the power
consumption of the UAV and the wireless charging process. Unlike the previous
works, we solve the problem by a designed deep neural network. The model is
trained using a deep reinforcement learning method offline, and is used to
optimize the UAV routing problem online. On small and large scale instances,
the proposed model runs from four times to 500 times faster than Google
OR-tools, the state-of-the-art combinatorial optimization solver, with
identical solution quality. It also outperforms different types of heuristic
and local search methods in terms of both run-time and optimality. In addition,
once the model is trained, it can scale to new generated problem instances with
arbitrary topology that are not seen during training. The proposed method is
practically applicable when the problem scale is large and the response time is
crucial."#
computer science#computing research repository#machine learning#Efficient Neural Neighborhood Search for Pickup and Delivery Problems#Yining Ma, Jingwen Li, Zhiguang Cao, Wen Song, Hongliang Guo, Yuejiao Gong, Yeow Meng Chee#"We present an efficient Neural Neighborhood Search (N2S) approach for pickup
and delivery problems (PDPs). In specific, we design a powerful Synthesis
Attention that allows the vanilla self-attention to synthesize various types of
features regarding a route solution. We also exploit two customized decoders
that automatically learn to perform removal and reinsertion of a
pickup-delivery node pair to tackle the precedence constraint. Additionally, a
diversity enhancement scheme is leveraged to further ameliorate the
performance. Our N2S is generic, and extensive experiments on two canonical PDP
variants show that it can produce state-of-the-art results among existing
neural methods. Moreover, it even outstrips the well-known LKH3 solver on the
more constrained PDP variant. Our implementation for N2S is available online."#
computer science#computing research repository#machine learning#Trusted Multi-View Classification with Dynamic Evidential Fusion#Zongbo Han, Changqing Zhang, Huazhu Fu, Joey Tianyi Zhou#"Existing multi-view classification algorithms focus on promoting accuracy by
exploiting different views, typically integrating them into common
representations for follow-up tasks. Although effective, it is also crucial to
ensure the reliability of both the multi-view integration and the final
decision, especially for noisy, corrupted and out-of-distribution data.
Dynamically assessing the trustworthiness of each view for different samples
could provide reliable integration. This can be achieved through uncertainty
estimation. With this in mind, we propose a novel multi-view classification
algorithm, termed trusted multi-view classification (TMC), providing a new
paradigm for multi-view learning by dynamically integrating different views at
an evidence level. The proposed TMC can promote classification reliability by
considering evidence from each view. Specifically, we introduce the variational
Dirichlet to characterize the distribution of the class probabilities,
parameterized with evidence from different views and integrated with the
Dempster-Shafer theory. The unified learning framework induces accurate
uncertainty and accordingly endows the model with both reliability and
robustness against possible noise or corruption. Both theoretical and
experimental results validate the effectiveness of the proposed model in
accuracy, robustness and trustworthiness."#
computer science#computing research repository#machine learning#Imitation Learning from Observations under Transition Model Disparity#Tanmay Gangwani, Yuan Zhou, Jian Peng#"Learning to perform tasks by leveraging a dataset of expert observations,
also known as imitation learning from observations (ILO), is an important
paradigm for learning skills without access to the expert reward function or
the expert actions. We consider ILO in the setting where the expert and the
learner agents operate in different environments, with the source of the
discrepancy being the transition dynamics model. Recent methods for scalable
ILO utilize adversarial learning to match the state-transition distributions of
the expert and the learner, an approach that becomes challenging when the
dynamics are dissimilar. In this work, we propose an algorithm that trains an
intermediary policy in the learner environment and uses it as a surrogate
expert for the learner. The intermediary policy is learned such that the state
transitions generated by it are close to the state transitions in the expert
dataset. To derive a practical and scalable algorithm, we employ concepts from
prior work on estimating the support of a probability distribution. Experiments
using MuJoCo locomotion tasks highlight that our method compares favorably to
the baselines for ILO with transition dynamics mismatch."#
computer science#computing research repository#machine learning#Improving Deep Learning Model Robustness Against Adversarial Attack by  Increasing the Network Capacity#Marco Marchetti, Edmond S. L. Ho#"Nowadays, we are more and more reliant on Deep Learning (DL) models and thus
it is essential to safeguard the security of these systems. This paper explores
the security issues in Deep Learning and analyses, through the use of
experiments, the way forward to build more resilient models. Experiments are
conducted to identify the strengths and weaknesses of a new approach to improve
the robustness of DL models against adversarial attacks. The results show
improvements and new ideas that can be used as recommendations for researchers
and practitioners to create increasingly better DL algorithms."#
computer science#computing research repository#machine learning#Learning Symmetric Embeddings for Equivariant World Models#Jung Yeon Park, Ondrej Biza, Linfeng Zhao, Jan Willem van de Meent, Robin Walters#"Incorporating symmetries can lead to highly data-efficient and generalizable
models by defining equivalence classes of data samples related by
transformations. However, characterizing how transformations act on input data
is often difficult, limiting the applicability of equivariant models. We
propose learning symmetric embedding networks (SENs) that encode an input space
(e.g. images), where we do not know the effect of transformations (e.g.
rotations), to a feature space that transforms in a known manner under these
operations. This network can be trained end-to-end with an equivariant task
network to learn an explicitly symmetric representation. We validate this
approach in the context of equivariant transition models with 3 distinct forms
of symmetry. Our experiments demonstrate that SENs facilitate the application
of equivariant networks to data with complex symmetry representations.
Moreover, doing so can yield improvements in accuracy and generalization
relative to both fully-equivariant and non-equivariant baselines."#
computer science#computing research repository#machine learning#Randomly Initialized Alternating Least Squares: Fast Convergence for  Matrix Sensing#Kiryung Lee, Dominik Stöger#"We consider the problem of reconstructing rank-one matrices from random
linear measurements, a task that appears in a variety of problems in signal
processing, statistics, and machine learning. In this paper, we focus on the
Alternating Least Squares (ALS) method. While this algorithm has been studied
in a number of previous works, most of them only show convergence from an
initialization close to the true solution and thus require a carefully designed
initialization scheme. However, random initialization has often been preferred
by practitioners as it is model-agnostic. In this paper, we show that ALS with
random initialization converges to the true solution with
$\varepsilon$-accuracy in $O(\log n + \log (1/\varepsilon)) $ iterations using
only a near-optimal amount of samples, where we assume the measurement matrices
to be i.i.d. Gaussian and where by $n$ we denote the ambient dimension. Key to
our proof is the observation that the trajectory of the ALS iterates only
depends very mildly on certain entries of the random measurement matrices.
Numerical experiments corroborate our theoretical predictions."#
computer science#computing research repository#machine learning#Do Users Benefit From Interpretable Vision? A User Study, Baseline, And  Dataset#Leon Sixt, Martin Schuessler, Oana-Iuliana Popescu, Philipp Weiß, Tim Landgraf#"A variety of methods exist to explain image classification models. However,
whether they provide any benefit to users over simply comparing various inputs
and the model's respective predictions remains unclear. We conducted a user
study (N=240) to test how such a baseline explanation technique performs
against concept-based and counterfactual explanations. To this end, we
contribute a synthetic dataset generator capable of biasing individual
attributes and quantifying their relevance to the model. In a study, we assess
if participants can identify the relevant set of attributes compared to the
ground-truth. Our results show that the baseline outperformed concept-based
explanations. Counterfactual explanations from an invertible neural network
performed similarly as the baseline. Still, they allowed users to identify some
attributes more accurately. Our results highlight the importance of measuring
how well users can reason about biases of a model, rather than solely relying
on technical evaluations or proxy tasks. We open-source our study and dataset
so it can serve as a blue-print for future studies. For code see,"#
computer science#computing research repository#machine learning#Predicting Real-time Scientific Experiments Using Transformer models and  Reinforcement Learning#Juan Manuel Parrilla-Gutierrez#"Life and physical sciences have always been quick to adopt the latest
advances in machine learning to accelerate scientific discovery. Examples of
this are cell segmentation or cancer detection. Nevertheless, these exceptional
results are based on mining previously created datasets to discover patterns or
trends. Recent advances in AI have been demonstrated in real-time scenarios
like self-driving cars or playing video games. However, these new techniques
have not seen widespread adoption in life or physical sciences because
experimentation can be slow. To tackle this limitation, this work aims to adapt
generative learning algorithms to model scientific experiments and accelerate
their discovery using in-silico simulations. We particularly focused on
real-time experiments, aiming to model how they react to user inputs. To
achieve this, here we present an encoder-decoder architecture based on the
Transformer model to simulate real-time scientific experimentation, predict its
future behaviour and manipulate it on a step-by-step basis. As a proof of
concept, this architecture was trained to map a set of mechanical inputs to the
oscillations generated by a chemical reaction. The model was paired with a
Reinforcement Learning controller to show how the simulated chemistry can be
manipulated in real-time towards user-defined behaviours. Our results
demonstrate how generative learning can model real-time scientific
experimentation to track how it changes through time as the user manipulates
it, and how the trained models can be paired with optimisation algorithms to
discover new phenomena beyond the physical limitations of lab experimentation.
This work paves the way towards building surrogate systems where physical
experimentation interacts with machine learning on a step-by-step basis."#
computer science#computing research repository#machine learning#Online Deep Learning from Doubly-Streaming Data#Heng Lian, John Scovil Atwood, Bojian Hou, Jian Wu, Yi He#"This paper investigates a new online learning problem with doubly-streaming
data, where the data streams are described by feature spaces that constantly
evolve, with new features emerging and old features fading away. The challenges
of this problem are two folds: 1) Data samples ceaselessly flowing in may carry
shifted patterns over time, requiring learners to update hence adapt
on-the-fly. 2) Newly emerging features are described by very few samples,
resulting in weak learners that tend to make error predictions. A plausible
idea to overcome the challenges is to establish relationship between the
pre-and-post evolving feature spaces, so that an online learner can leverage
the knowledge learned from the old features to better the learning performance
on the new features. Unfortunately, this idea does not scale up to
high-dimensional media streams with complex feature interplay, which suffers an
tradeoff between onlineness (biasing shallow learners) and
expressiveness(requiring deep learners). Motivated by this, we propose a novel
OLD^3S paradigm, where a shared latent subspace is discovered to summarize
information from the old and new feature spaces, building intermediate feature
mapping relationship. A key trait of OLD^3S is to treat the model capacity as a
learnable semantics, yields optimal model depth and parameters jointly, in
accordance with the complexity and non-linearity of the input data streams in
an online fashion. Both theoretical analyses and empirical studies substantiate
the viability and effectiveness of our proposal."#
computer science#computing research repository#machine learning#Faculty Distillation with Optimal Transport#Su Lu, Han-Jia Ye, De-Chuan Zhan#"Knowledge distillation (KD) has shown its effectiveness in improving a
student classifier given a suitable teacher. The outpouring of diverse and
plentiful pre-trained models may provide abundant teacher resources for KD.
However, these models are often trained on different tasks from the student,
which requires the student to precisely select the most contributive teacher
and enable KD across different label spaces. These restrictions disclose the
insufficiency of standard KD and motivate us to study a new paradigm called
faculty distillation. Given a group of teachers (faculty), a student needs to
select the most relevant teacher and perform generalized knowledge reuse. To
this end, we propose to link teacher's task and student's task by optimal
transport. Based on the semantic relationship between their label spaces, we
can bridge the support gap between output distributions by minimizing Sinkhorn
distances. The transportation cost also acts as a measurement of teachers'
adaptability so that we can rank the teachers efficiently according to their
relatedness. Experiments under various settings demonstrate the succinctness
and versatility of our method."#
computer science#computing research repository#machine learning#Task-Induced Representation Learning#Jun Yamada, Karl Pertsch, Anisha Gunjal, Joseph J. Lim#"In this work, we evaluate the effectiveness of representation learning
approaches for decision making in visually complex environments. Representation
learning is essential for effective reinforcement learning (RL) from
high-dimensional inputs. Unsupervised representation learning approaches based
on reconstruction, prediction or contrastive learning have shown substantial
learning efficiency gains. Yet, they have mostly been evaluated in clean
laboratory or simulated settings. In contrast, real environments are visually
complex and contain substantial amounts of clutter and distractors.
Unsupervised representations will learn to model such distractors, potentially
impairing the agent's learning efficiency. In contrast, an alternative class of
approaches, which we call task-induced representation learning, leverages task
information such as rewards or demonstrations from prior tasks to focus on
task-relevant parts of the scene and ignore distractors. We investigate the
effectiveness of unsupervised and task-induced representation learning
approaches on four visually complex environments, from Distracting DMControl to
the CARLA driving simulator. For both, RL and imitation learning, we find that
representation learning generally improves sample efficiency on unseen tasks
even in visually complex scenes and that task-induced representations can
double learning efficiency compared to unsupervised alternatives. Code is
available at"#
computer science#computing research repository#machine learning#Algorithms and Theory for Supervised Gradual Domain Adaptation#Jing Dong, Shiji Zhou, Baoxiang Wang, Han Zhao#"The phenomenon of data distribution evolving over time has been observed in a
range of applications, calling the needs of adaptive learning algorithms. We
thus study the problem of supervised gradual domain adaptation, where labeled
data from shifting distributions are available to the learner along the
trajectory, and we aim to learn a classifier on a target data distribution of
interest. Under this setting, we provide the first generalization upper bound
on the learning error under mild assumptions. Our results are algorithm
agnostic, general for a range of loss functions, and only depend linearly on
the averaged learning error across the trajectory. This shows significant
improvement compared to the previous upper bound for unsupervised gradual
domain adaptation, where the learning error on the target domain depends
exponentially on the initial error on the source domain. Compared with the
offline setting of learning from multiple domains, our results also suggest the
potential benefits of the temporal structure among different domains in
adapting to the target one. Empirically, our theoretical results imply that
learning proper representations across the domains will effectively mitigate
the learning errors. Motivated by these theoretical insights, we propose a
min-max learning objective to learn the representation and classifier
simultaneously. Experimental results on both semi-synthetic and large-scale
real datasets corroborate our findings and demonstrate the effectiveness of our
objectives."#
computer science#computing research repository#machine learning#Enable Deep Learning on Mobile Devices: Methods, Systems, and  Applications#Han Cai, Ji Lin, Yujun Lin, Zhijian Liu, Haotian Tang, Hanrui Wang, Ligeng Zhu, Song Han#"Deep neural networks (DNNs) have achieved unprecedented success in the field
of artificial intelligence (AI), including computer vision, natural language
processing and speech recognition. However, their superior performance comes at
the considerable cost of computational complexity, which greatly hinders their
applications in many resource-constrained devices, such as mobile phones and
Internet of Things (IoT) devices. Therefore, methods and techniques that are
able to lift the efficiency bottleneck while preserving the high accuracy of
DNNs are in great demand in order to enable numerous edge AI applications. This
paper provides an overview of efficient deep learning methods, systems and
applications. We start from introducing popular model compression methods,
including pruning, factorization, quantization as well as compact model design.
To reduce the large design cost of these manual solutions, we discuss the
AutoML framework for each of them, such as neural architecture search (NAS) and
automated pruning and quantization. We then cover efficient on-device training
to enable user customization based on the local data on mobile devices. Apart
from general acceleration techniques, we also showcase several task-specific
accelerations for point cloud, video and natural language processing by
exploiting their spatial sparsity and temporal/token redundancy. Finally, to
support all these algorithmic advancements, we introduce the efficient deep
learning system design from both software and hardware perspectives."#
computer science#computing research repository#machine learning#Graph Neural Network-based Early Bearing Fault Detection#Xusheng Du, Jiong Yu#"Early detection of faults is of importance to avoid catastrophic accidents
and ensure safe operation of machinery. A novel graph neural network-based
fault detection method is proposed to build a bridge between AI and real-world
running mechanical systems. First, the vibration signals, which are Euclidean
structured data, are converted into graph (non-Euclidean structured data), so
that the vibration signals, which are originally independent of each other, are
correlated with each other. Second, inputs the dataset together with its
corresponding graph into the GNN for training, which contains graphs in each
hidden layer of the network, enabling the graph neural network to learn the
feature values of itself and its neighbors, and the obtained early features
have stronger discriminability. Finally, determines the top-n objects that are
difficult to reconstruct in the output layer of the GNN as fault objects. A
public datasets of bearings have been used to verify the effectiveness of the
proposed method. We find that the proposed method can successfully detect
faulty objects that are mixed in the normal object region."#
computer science#computing research repository#machine learning#Computing the Collection of Good Models for Rule Lists#Kota Mata, Kentaro Kanamori, Hiroki Arimura#"Since the seminal paper by Breiman in 2001, who pointed out a potential harm
of prediction multiplicities from the view of explainable AI, global analysis
of a collection of all good models, also known as a `Rashomon set,' has been
attracted much attention for the last years. Since finding such a set of good
models is a hard computational problem, there have been only a few algorithms
for the problem so far, most of which are either approximate or incomplete. To
overcome this difficulty, we study efficient enumeration of all good models for
a subclass of interpretable models, called rule lists. Based on a
state-of-the-art optimal rule list learner, CORELS, proposed by Angelino et al.
in 2017, we present an efficient enumeration algorithm CorelsEnum for exactly
computing a set of all good models using polynomial space in input size, given
a dataset and a error tolerance from an optimal model. By experiments with the
COMPAS dataset on recidivism prediction, our algorithm CorelsEnum successfully
enumerated all of several tens of thousands of good rule lists of length at
most $\ell = 3$ in around 1,000 seconds, while a state-of-the-art top-$K$ rule
list learner based on Lawler's method combined with CORELS, proposed by Hara
and Ishihata in 2018, found only 40 models until the timeout of 6,000 seconds.
For global analysis, we conducted experiments for characterizing the Rashomon
set, and observed large diversity of models in predictive multiplicity and
fairness of models."#
computer science#computing research repository#machine learning#Satellite Image Time Series Analysis for Big Earth Observation Data#Rolf Simoes, Gilberto Camara, Gilberto Queiroz, Felipe Souza, Pedro R. Andrade, Lorena Santos, Alexandre Carvalho, Karine Ferreira#"The development of analytical software for big Earth observation data faces
several challenges. Designers need to balance between conflicting factors.
Solutions that are efficient for specific hardware architectures can not be
used in other environments. Packages that work on generic hardware and open
standards will not have the same performance as dedicated solutions. Software
that assumes that its users are computer programmers are flexible but may be
difficult to learn for a wide audience. This paper describes sits, an
open-source R package for satellite image time series analysis using machine
learning. To allow experts to use satellite imagery to the fullest extent, sits
adopts a time-first, space-later approach. It supports the complete cycle of
data analysis for land classification. Its API provides a simple but powerful
set of functions. The software works in different cloud computing environments.
Satellite image time series are input to machine learning classifiers, and the
results are post-processed using spatial smoothing. Since machine learning
methods need accurate training data, sits includes methods for quality
assessment of training samples. The software also provides methods for
validation and accuracy measurement. The package thus comprises a production
environment for big EO data analysis. We show that this approach produces high
accuracy for land use and land cover maps through a case study in the Cerrado
biome, one of the world's fast moving agricultural frontiers for the year 2018."#
computer science#computing research repository#machine learning#The Multiscale Structure of Neural Network Loss Functions: The Effect on  Optimization and Origin#Chao Ma, Lei Wu, Lexing Ying#"Local quadratic approximation has been extensively used to study the
optimization of neural network loss functions around the minimum. Though, it
usually holds in a very small neighborhood of the minimum, and cannot explain
many phenomena observed during the optimization process. In this work, we study
the structure of neural network loss functions and its implication on
optimization in a region beyond the reach of good quadratic approximation.
Numerically, we observe that neural network loss functions possesses a
multiscale structure, manifested in two ways: (1) in a neighborhood of minima,
the loss mixes a continuum of scales and grows subquadratically, and (2) in a
larger region, the loss shows several separate scales clearly. Using the
subquadratic growth, we are able to explain the Edge of Stability phenomenon[4]
observed for gradient descent (GD) method. Using the separate scales, we
explain the working mechanism of learning rate decay by simple examples.
Finally, we study the origin of the multiscale structure and propose that the
non-uniformity of training data is one of its cause. By constructing a
two-layer neural network problem we show that training data with different
magnitudes give rise to different scales of the loss function, producing
subquadratic growth or multiple separate scales."#
computer science#computing research repository#machine learning#Piecewise-Linear Activations or Analytic Activation Functions: Which  Produce More Expressive Neural Networks?#Anastasis Kratsios, Behnoosh Zamanlooy#"Many currently available universal approximation theorems affirm that deep
feedforward networks defined using any suitable activation function can
approximate any integrable function locally in $L^1$-norm. Though different
approximation rates are available for deep neural networks defined using other
classes of activation functions, there is little explanation for the
empirically confirmed advantage that ReLU networks exhibit over their classical
(e.g. sigmoidal) counterparts. Our main result demonstrates that deep networks
with piecewise linear activation (e.g. ReLU or PReLU) are fundamentally more
expressive than deep feedforward networks with analytic (e.g. sigmoid, Swish,
GeLU, or Softplus). More specifically, we construct a strict refinement of the
topology on the space $L^1_{\operatorname{loc}}(\mathbb{R}^d,\mathbb{R}^D)$ of
locally Lebesgue-integrable functions, in which the set of deep ReLU networks
with (bilinear) pooling $\operatorname{NN}^{\operatorname{ReLU} +
\operatorname{Pool}}$ is dense (i.e. universal) but the set of deep feedforward
networks defined using any combination of analytic activation functions with
(or without) pooling layers $\operatorname{NN}^{\omega+\operatorname{Pool}}$ is
not dense (i.e. not universal). Our main result is further explained by
\textit{quantitatively} demonstrating that this ""separation phenomenon"" between
the networks in $\operatorname{NN}^{\operatorname{ReLU}+\operatorname{Pool}}$
and those in $\operatorname{NN}^{\omega+\operatorname{Pool}}$ by showing that
the networks in $\operatorname{NN}^{\operatorname{ReLU}}$ are capable of
approximate any compactly supported Lipschitz function while
\textit{simultaneously} approximating its essential support; whereas, the
networks in $\operatorname{NN}^{\omega+\operatorname{pool}}$ cannot."#
computer science#computing research repository#machine learning#Farmer's Assistant: A Machine Learning Based Application for  Agricultural Solutions#Shloka Gupta, Akshay Chopade, Nishit Jain, Aparna Bhonde#"Farmers face several challenges when growing crops like uncertain irrigation,
poor soil quality, etc. Especially in India, a major fraction of farmers do not
have the knowledge to select appropriate crops and fertilizers. Moreover, crop
failure due to disease causes a significant loss to the farmers, as well as the
consumers. While there have been recent developments in the automated detection
of these diseases using Machine Learning techniques, the utilization of Deep
Learning has not been fully explored. Additionally, such models are not easy to
use because of the high-quality data used in their training, lack of
computational power, and poor generalizability of the models. To this end, we
create an open-source easy-to-use web application to address some of these
issues which may help improve crop production. In particular, we support crop
recommendation, fertilizer recommendation, plant disease prediction, and an
interactive news-feed. In addition, we also use interpretability techniques in
an attempt to explain the prediction made by our disease detection model."#
computer science#computing research repository#machine learning#COVID-Net Biochem: An Explainability-driven Framework to Building  Machine Learning Models for Predicting Survival and Kidney Injury of COVID-19  Patients from Clinical and Biochemistry Data#Hossein Aboutalebi, Maya Pavlova, Mohammad Javad Shafiee, Adrian Florea, Andrew Hryniowski, Alexander Wong#"Ever since the declaration of COVID-19 as a pandemic by the World Health
Organization in 2020, the world has continued to struggle in controlling and
containing the spread of the COVID-19 pandemic caused by the SARS-CoV-2 virus.
This has been especially challenging with the rise of the Omicron variant and
its subvariants and recombinants, which has led to a significant increase in
patients seeking treatment and has put a tremendous burden on hospitals and
healthcare systems. A major challenge faced during the pandemic has been the
prediction of survival and the risk for additional injuries in individual
patients, which requires significant clinical expertise and additional
resources to avoid further complications. In this study we propose COVID-Net
Biochem, an explainability-driven framework for building machine learning
models to predict patient survival and the chance of developing kidney injury
during hospitalization from clinical and biochemistry data in a transparent and
systematic manner. In the first ""clinician-guided initial design"" phase, we
prepared a benchmark dataset of carefully selected clinical and biochemistry
data based on clinician assessment, which were curated from a patient cohort of
1366 patients at Stony Brook University. A collection of different machine
learning models with a diversity of gradient based boosting tree architectures
and deep transformer architectures was designed and trained specifically for
survival and kidney injury prediction based on the carefully selected clinical
and biochemical markers."#
computer science#computing research repository#machine learning#An empirical study of the effect of background data size on the  stability of SHapley Additive exPlanations (SHAP) for deep learning models#Han Yuan, Mingxuan Liu, Michael Krauthammer, Lican Kang, Chenkui Miao, Ying Wu#"Nowadays, the interpretation of why a machine learning (ML) model makes
certain inferences is as crucial as the accuracy of such inferences. Some ML
models like the decision tree possess inherent interpretability that can be
directly comprehended by humans. Others like artificial neural networks (ANN),
however, rely on external methods to uncover the deduction mechanism. SHapley
Additive exPlanations (SHAP) is one of such external methods, which requires a
background dataset when interpreting ANNs. Generally, a background dataset
consists of instances randomly sampled from the training dataset. However, the
sampling size and its effect on SHAP remain to be unexplored. In our empirical
study on the MIMIC-III dataset, we show that the two core explanations - SHAP
values and variable rankings fluctuate when using different background datasets
acquired from random sampling, indicating that users cannot unquestioningly
trust the one-shot interpretation from SHAP. Luckily, such fluctuation
decreases with the increase of the background dataset size. Also, we notice an
U-shape in the stability assessment of SHAP variable rankings, demonstrating
that SHAP is more reliable in ranking the most and least important variables
compared to moderately important ones. Overall, our results suggest that users
should take into account how background data affects SHAP results, with
improved SHAP stability as the background sample size increases."#
computer science#computing research repository#machine learning#Skill-based Meta-Reinforcement Learning#Taewook Nam, Shao-Hua Sun, Karl Pertsch, Sung Ju Hwang, Joseph J Lim#"While deep reinforcement learning methods have shown impressive results in
robot learning, their sample inefficiency makes the learning of complex,
long-horizon behaviors with real robot systems infeasible. To mitigate this
issue, meta-reinforcement learning methods aim to enable fast learning on novel
tasks by learning how to learn. Yet, the application has been limited to
short-horizon tasks with dense rewards. To enable learning long-horizon
behaviors, recent works have explored leveraging prior experience in the form
of offline datasets without reward or task annotations. While these approaches
yield improved sample efficiency, millions of interactions with environments
are still required to solve complex tasks. In this work, we devise a method
that enables meta-learning on long-horizon, sparse-reward tasks, allowing us to
solve unseen target tasks with orders of magnitude fewer environment
interactions. Our core idea is to leverage prior experience extracted from
offline datasets during meta-learning. Specifically, we propose to (1) extract
reusable skills and a skill prior from offline datasets, (2) meta-train a
high-level policy that learns to efficiently compose learned skills into
long-horizon behaviors, and (3) rapidly adapt the meta-trained policy to solve
an unseen target task. Experimental results on continuous control tasks in
navigation and manipulation demonstrate that the proposed method can
efficiently solve long-horizon novel target tasks by combining the strengths of
meta-learning and the usage of offline datasets, while prior approaches in RL,
meta-RL, and multi-task RL require substantially more environment interactions
to solve the tasks."#
physics#physics#applied physics#Superconducting bimodal ionic photo-memristor#Ralph El Hage, Vincent Humbert, Victor Rouco, Anke Sander, Jérôme Charliac, Salvatore Mesoraca, Juan Trastoy, Javier Briatico, Jacobo Santamaría, Javier E. Villegas#"Memristive circuit elements constitute a cornerstone for novel electronic
applications, such as neuromorphic computing, called to revolutionize
information technologies. By definition, memristors are sensitive to the
history of electrical stimuli, to which they respond by varying their
electrical resistance across a continuum of nonvolatile states. Recently, much
effort has been devoted to developing devices that present an analogous
response to optical excitation. Here we realize a new class of device, a
tunnelling photo-memristor, whose behaviour is bimodal: both electrical and
optical stimuli can trigger the switching across resistance states in a way
determined by the dual optical-electrical history. This unique behaviour is
obtained in a device of ultimate simplicity: an interface between a
high-temperature superconductor and a transparent semiconductor. The
microscopic mechanism at play is a reversible nanoscale redox reaction between
both materials, whose oxygen content determines the electron tunnelling rate
across their interface. Oxygen exchange is controlled here via illumination by
exploiting a competition between electrochemistry, photovoltaic effects and
photo-assisted ion migration. In addition to their fundamental interest, the
unveiled electro-optic memory effects have considerable technological
potential. Especially in combination with high-temperature superconductivity
which, beyond facilitating the high connectivity required in neuromorphic
circuits, brings photo-memristive effects to the realm of superconducting
electronics."#
physics#physics#applied physics#Graphene on Silicon Hybrid Field-Effect Transistors#Mykola Fomin, Francisco Pasadas, Enrique Marin, Alberto Medina Rull, Francisco Ruiz, Andres Godoy, Ihor Zadorozhnyi, Guillermo Beltramo, Fabian Brings, Svetlana Vitusevich, Andreas Offenhaeusser, Dmitry Kireev#"The combination of graphene with silicon in hybrid devices has attracted
attention extensively over the last decade. Most of such devices were proposed
for photonics and radiofrequency applications. In this work, we present a
unique technology of graphene-on-silicon heterostructures and their properties
as solution-gated transistors. The graphene-on-Silicon field-effect transistors
(GoSFETs) were fabricated exploiting various conformations of drain-source
regions doping and channel material dimensions. The fabricated devices were
electrically characterized demonstrating hybrid behavior with features specific
to both graphene and silicon. Although GoSFET's transconductance and carrier's
mobility were found to be lower than in conventional silicon and graphene
field-effect transistors (SiFETs and GFETs), it was demonstrated that the
combination of both materials within the hybrid channel contribute uniquely to
the charge carrier transport. A comprehensive physics-based compact modeling
was specifically developed, showing excellent agreement with the experimental
data. The model is employed to rationalize the observed hybrid behavior as the
theoretical results from the electrostatics and the carrier transport under a
drift-diffusion approach show that graphene acts as a shield for the silicon
channel, giving rise to a non-uniform potential distribution along it,
especially at the subthreshold region. This graphene screening effect is shown
to strongly affect the device subthreshold swing when compared against a
conventional SiFET due to a non-negligible diffusion current in this operation
regime."#
physics#physics#applied physics#Nusselt number for steady periodically developed heat transfer in micro-  and mini-channels with arrays of offset strip fins subject to a uniform heat  flux#Arthur Vangeffelen, Geert Buckinx, Maria Rosaria Vetrano, Martine Baelmans#"In this work, the Nusselt number is examined for periodically developed heat
transfer in micro- and mini-channels with arrays of offset strip fins, subject
to a constant heat flux. The Nusselt number is defined on the basis of a heat
transfer coefficient which represents the spatially constant macro-scale
temperature difference between the fluid and solid during conjugate heat
transfer. Its values are determined numerically on a single unit cell of the
array for Reynolds numbers between 1 and 600. Two combinations of the Prandtl
number and the thermal conductivity ratio are selected, corresponding to air
and water. It is shown that the Nusselt number correlations from the literature
mainly apply to air in the transitional flow regime in larger conventional
channels if the wall temperature remains uniform. As a result, they do not
correctly capture the observed trends for the Nusselt number in micro- and
mini-channels subject to a constant heat flux. Therefore, new Nusselt number
correlations, obtained through a least-squares fitting of 2282 numerical
simulations, are presented for air and water. The suitability of these
correlations is assessed via the Bayesian approach for parameter estimation and
model validation. The correlations respect the observed asymptotic trends and
limits of the Nusselt number for all the geometrical parameters of the offset
strip fins. In addition, they predict a linear dependence of the Nusselt number
on the Reynolds number, in good agreement with the data from this work.
Nevertheless, a detailed analysis reveals a more complex scaling of the Nusselt
number with the Reynolds number, closely related to the underlying flow
regimes, particularly the weak and strong inertia regimes. Finally, through 62
additional simulations, the influence of the material properties on the Nusselt
number is illustrated and compared to the available literature."#
physics#physics#applied physics#Characterization of GaN-based HEMTs Down to 4.2 K for Cryogenic  Applications#Bolun Zeng, Haochen Zhang, Zikun Xiang, Chao Luo, Yuanke Zhang, Mingjie Weng, Qiwen Xue, Sirui Hu, Yue Sun, Lei Yang, Haiding Sun, Guoping Guo#"The cryogenic performance of GaN-based HEMTs (high-electron-mobility
transistors) is systematically investigated by the direct current (DC) and
low-frequency noise (LFN) characteristics within the temperature (T) range from
300 K to 4.2 K. The important electrical merits of the device, including drain
saturation current (IDsat), on-resistance (RON), transductance, subthreshold
swing (SS), gate leakage current, and Schottky barrier height, are
comprehensively characterized and their temperature-dependent behavior was
statistically analyzed. In addition, the LFN of the device shows an evident
behavior of 1/f noise from 10 Hz to 10 kHz in the measured temperature range
and can be significantly reduced at cryogenic temperature. These results are of
great importance to motivate further studies into the GaN-based cryo-devices
and systems."#
physics#physics#applied physics#Dynamically controlled double-well optical potential for colloidal  particles#Thalyta Tavares Martins, Sérgio Ricardo Muniz#"This preliminary study presents a simple modulation scheme to dynamically
create time-averaged optical potentials to trap colloidal particles using
acousto-optical modulation. The method provides access to control
experimentally relevant parameters of a tunable double-well potential. We show
experimental data successfully adjusting the trapping distance in the range
20-2000 nm and discuss situations arising when reconstructing time-averaged
optical potentials from trapped particle data. This is the first step towards
studying colloidal particles in dynamically modulated optical potentials to
explore the stochastic thermodynamics of mesoscopic systems and small-scale
thermo-mechanical machines."#
physics#physics#applied physics#Design of Cryogenic Fully Differential Gain Boosting-OTA by the  $g_{m}/I_{d}$ methodology used for a 14 bit Pipelined-SAR ADC#Mingjie Wen, Chao Luo, BoLun Zeng, Guoping Guo#"Quantum computing (QC) requires cryogenic electronic circuits as control and
readout sub-systems of quantum chips to meet the qubit scale-up challenges.At
this temperature,MOSFETs transistors exhibition many changes such as higher
threshold voltage,higher mobility,and steeper substhreshold slope.We present a
cryogenic fully differential gain boosting-OTA used for a 14 bit Pipelined-SAR
ADC operating at 4.2K as the readout circuit for semiconductor-based quantum
computing system.Using $g_{m}/I_{d}$ methodology to get pre-computed lookup
tables based on the cryogenic 110nm BSIM4 model.The proposed OTA achieves very
high unity-gain frequency@1.23GHz and open-loop low frequency gain@101dB.The
total power consumption is 2.66mW at 4.2K,and a setting accuracy better than
0.01\% with $f_{-3dB}$ of 37MHz in a closed-loop application."#
physics#physics#applied physics#Wireless powering efficiency assessment for deep-body implantable  devices#Icaro V. Soares, Mingxiang Gao, Zvonimir Sipus, Anja K. Skrivervik, Denys Nikolayev#"Several frequency-dependent mechanisms restrict the maximum achievable
efficiency for wireless powering implantable bioelectric devices. Similarly,
many mathematical formulations have been proposed to evaluate the effect of
these mechanisms as well as predict this maximum efficiency and the
corresponding optimum frequency. However, most of these methods consider a
simplified model, and they cannot tackle some realistic aspects of implantable
wireless power transfer. Therefore, this paper proposed a novel approach that
can analyze the efficiency in anatomical models and provide insightful
information on achieving this optimum operation. First, this approach is
validated with a theoretical spherical wave expansion analysis, and the results
for a simplified spherical model and a bidimensional human pectoral model are
compared. Results have shown that even though a magnetic receiver outperforms
an electric one for near-field operation and both sources could be equally
employed in far-field range, it is in mid-field that the maximum efficiency is
achieved, with an optimum frequency between 1-5 GHz, depending on the
implantation depth. In addition, the receiver orientation is another factor
that affects the efficiency, with a maximum difference between the best and
worst-case scenarios around five times for an electric source and over 13 times
for the magnetic one. Finally, this approach is used to analyze the case of a
wirelessly powered deep-implanted pacemaker by an on-body transmitter and to
establish the parameters that lead to the maximum achievable efficiency."#
physics#physics#applied physics#Demonstration of Superconducting Optoelectronic Single-Photon Synapses#Saeed Khan, Bryce A. Primavera, Jeff Chiles, Adam N. McCaughan, Sonia M. Buckley, Alexander N. Tait, Adriana Lita, John Biesecker, Anna Fox, David Olaya, Richard P. Mirin, Sae Woo Nam, Jeffrey M. Shainline#"Superconducting optoelectronic hardware is being explored as a path towards
artificial spiking neural networks with unprecedented scales of complexity and
computational ability. Such hardware combines integrated-photonic components
for few-photon, light-speed communication with superconducting circuits for
fast, energy-efficient computation. Monolithic integration of superconducting
and photonic devices is necessary for the scaling of this technology. In the
present work, superconducting-nanowire single-photon detectors are
monolithically integrated with Josephson junctions for the first time, enabling
the realization of superconducting optoelectronic synapses. We present circuits
that perform analog weighting and temporal leaky integration of single-photon
presynaptic signals. Synaptic weighting is implemented in the electronic domain
so that binary, single-photon communication can be maintained. Records of
recent synaptic activity are locally stored as current in superconducting
loops. Dendritic and neuronal nonlinearities are implemented with a second
stage of Josephson circuitry. The hardware presents great design flexibility,
with demonstrated synaptic time constants spanning four orders of magnitude
(hundreds of nanoseconds to milliseconds). The synapses are responsive to
presynaptic spike rates exceeding 10 MHz and consume approximately 33 aJ of
dynamic power per synapse event before accounting for cooling. In addition to
neuromorphic hardware, these circuits introduce new avenues towards realizing
large-scale single-photon-detector arrays for diverse imaging, sensing, and
quantum communication applications."#
physics#physics#applied physics#In situ nonlinear Rayleigh wave technique to characterize the tensile  plastic deformation of stainless steel 316L#Changgong Kim, Kathryn H. Matlack#"The acoustic nonlinearity parameter(beta) is sensitive to dislocation
parameters, which continuously change during plastic deformation.
Dislocation-based damage in structures/components is the source of the failure;
thus, beta has been studied as a metric for non-destructive evaluation. This
work consists of two parts: the development of an in situ experimental setup
for nonlinear Rayleigh wave measurements, and characterization of the
dependence of beta on applied stress at different levels of initial plastic
strain. First, we introduce an experimental setup and methods for repeatable in
situ nonlinear ultrasonic measurements. Details on design considerations and
measurement schemes are provided. In the second part, beta was measured in situ
during an incremental monotonic tensile test. The measured \beta monotonically
decreases with plastic strain, but it is relatively insensitive to the applied
stress during elastic deformation. This result highlights three aspects of the
evolution of beta, which have not been sufficiently emphasized in prior work:
the apparent insensitivity of beta to the applied stress during elastic
deformation, decreasing beta with plastic deformation, and the saturation of
beta. We attribute the trend of decreasing beta to a scaling of beta with
monopole loop length during plastic deformation, which depends on initial
microstructure. The saturation of beta at 1.8% coincides with a planar-to-wavy
transition of dislocation structures. The in situ nonlinear ultrasonic
experimental method presented in this work is significant as the in situ
results can provide broader insights on beta and dislocation-based damage
evolution than ex situ measurements alone."#
physics#physics#applied physics#Fiber-optic multimode interference sensing: comprehensive  characterization and its potential for strain-insensitive temperature sensing#Kun Wang, Yosuke Mizuno, Xingchen Dong, Wolfgang Kurz, Maximilian Fink, Heeyoung Lee, Martin Jakobi, Alexander W. Koch#"A strain-insensitive temperature sensor based on multimode interference using
standard multimode fibers (MMFs) is proposed according to the comprehensive
study of the characteristics of the MMFs. The temperature and strain
dependences on the core diameter, numerical aperture (NA), and the length of
the MMF section in the single-mode--multimode--single-mode (SMS) fiber
structure are investigated experimentally. The results indicate that the larger
core diameter of the MMF leads to higher temperature sensitivity but lower
strain sensitivity (absolute values); the higher NA does not influence the
temperature sensitivity but results in higher absolute value of strain
sensitivity; the longer MMF section brings lower temperature sensitivity but
does not have an impact on strain sensitivity. These findings also contribute
to the theoretical analysis of the length dependence in the SMS fiber sensors.
Besides, the results of the characterization study show that the strain
sensitivity is relatively low, which brings a possibility to develop a
strain-insensitive temperature sensor. The proposed sensor is used for
temperature sensing while the strain is constantly applied from 0 to 1100
$\mu\epsilon$ with steps of 100 $\mu\epsilon$. The measured results are
consistent with the comprehensive study. The mean temperature sensitivity is
6.14 pm/$^{\circ}$C with a standard deviation of 0.39 pm/$^{\circ}$C, which
proves that the proposed temperature sensor exhibits good stability and is
insensitive to strain. We expect that these results will provide a profound
guideline to fiber sensors based on multimode interference."#
physics#physics#applied physics#Engineering bound states in the continuum at telecom wavelengths with  non-Bravais lattices#Shunsuke Murai, Diego R. Abujetas, Libei Liu, Gabriel W. Castellanos, Vincenzo Giannini, José A. Sánchez-Gil, Katsuhisa Tanaka, Jaime Gómez Rivas#"Various optical phenomena can be induced in periodic arrays of nanoparticles
by the radiative coupling of the local dipoles in each particle. Probably the
most impressive example is bound states in the continuum (BICs), which are
electromagnetic modes with a dispersion inside the light cone but infinite
lifetime, i.e., modes that cannot leak to the continuum. Symmetry-protected
BICs appear at highly symmetric points in the dispersion of periodic systems.
Although the addition of nonequivalent lattice points in a unit cell is an easy
and straightforward way of tuning the symmetry, BICs in such particle lattice,
i.e., non-Bravais lattice, are less explored among periodic systems. Starting
from a periodic square lattice of Si nanodisks, we have prepared three
non-Bravais lattices by detuning size and position of the second disk in the
unit cell. Diffraction-induced coupling excites magnetic/electric dipoles in
each nanodisk, producing two surface lattice resonances at the $\Gamma$ point
with a band gap in between. %of $\sim$ 41 meV.
The high/low energy branch becomes a BIC for the size/position-detuned array,
respectively, while both branches are bright (or leaky) when both size and
position are detuned simultaneously. The role of magnetic and electric
resonances in dielectric nanoparticles and the change of BIC to bright
character of the modes is explained by the two different origins of BICs in the
detuned arrays, which is further discussed with the aid of a coupled electric
and magnetic dipole model. This study gives a simple way of tuning BICs at
telecom wavelengths in non-Bravais lattices, including both plasmonic and
dielectric systems, thus scalable to a wide range of frequencies."#
physics#physics#applied physics#Honing in on a topological zero-bias conductance peak#Subhajit Pal, Colin Benjamin#"A popular signature of Majorana bound states in topological superconductors
is the zero-energy conductance peak with a height of $2e^2/h$. However, a
similar zero energy conductance peak with almost the same height can also arise
due to non-topological reasons. Here we show that these trivial and topological
zero energy conductance peaks can be distinguished via the zero energy local
density of states and local magnetization density of states. We find that the
zero-energy local density of states exhibits oscillations with a finite period
for a trivial zero-bias conductance peak. In contrast, these oscillations
disappear for the topological zero-bias conductance peak. On the other hand,
zero energy local magnetization density of states shows a periodic oscillation
for trivial zero-bias conductance peak, while for topological ZBCP, they
vanish. Our results suggest that zero-energy local density of states and local
magnetization density of states can be used as an experimental probe to
distinguish trivial zero energy conductance peak from topological zero energy
conductance peak."#
physics#physics#applied physics#Nuclear spin self compensation system for moving MEG sensing with  optical pumped atomic spin co-magnetometer#Yao Chen, Yintao Ma, Mingzhi Yu, Yanbin Wang, Ning Zhang, Libo Zhao, Zhuangde Jiang#"Recording the moving MEGs of a person in which a person's head could move
freely as we record the brain's magnetic field is a hot topic in recent years.
Traditionally, atomic magnetometers are utilized for moving MEGs recording and
a large compensation coil system is utilized for background magnetic field
compensation. Here we described a new potential candidate: an optically pumped
atomic co-magnetometer(OPACM) for moving MEGs recording. In the OPACM,
hyper-polarized nuclear spins could produce a magnetic field which will shield
the background fluctuation low frequency magnetic field noise while the the
fast changing MEGs signal could be recorded. The nuclear spins look like an
automatic magnetic field shields and dynamically compensate the fluctuated
background magnetic field noise. In this article, the magnetic field
compensation is studied theoretically and we find that the compensation is
closely related to several parameters such as the electron spin magnetic field,
the nuclear spin magnetic field and the holding magnetic field. Based on the
model, the magnetic field compensation could be optimized. We also
experimentally studied the magnetic field compensation and the responses of the
OPACM to different frequencies of magnetic field are measured. We show that the
OPACM owns a clear suppression of low frequency magnetic field under 1Hz and
response to magnetic field's frequencies around the band of the MEGs. Magnetic
field sensitivity of $3fT/Hz^{1/2}$ has been achieved. Finally, we do a
simulation for the OPACM as it is utilized for moving MEGs recording. For
comparison, the traditional compensation system for moving MEGs recording is
based on a coil which is around 2m in dimension while our compensation system
is only 2mm in dimension. Moreover, our compensation system could work in situ
and will not affect each other."#
physics#physics#applied physics#Observation of Dirac hierarchy in three-dimensional acoustic topological  insulators#Linyun Yang, Yin Wang, Yan Meng, Zhenxiao Zhu, Xiang Xi, Bei Yan, Shuxin Lin, Jingming Chen, Bin-jie Shi, Yong Ge, Shou-qi Yuan, Hong-xiang Sun, Gui-Geng Liu, Yihao Yang, Zhen Gao#"Dirac cones (DCs) play a pivotal role in various unique phenomena ranging
from massless electrons in graphene to robust surface states in topological
insulators (TIs). Recent studies have theoretically revealed a full Dirac
hierarchy comprising an eightfold bulk DC, a fourfold surface DC, and a twofold
hinge DC, associated with a hierarchy of topological phases including
first-order to third-order three-dimensional (3D) topological insulators, using
the same 3D base lattice. Here, we report the first experimental observation of
the Dirac hierarchy in 3D acoustic TIs. Using acoustic measurements, we
unambiguously reveal that lifting of multifold DCs in each hierarchy can induce
two-dimensional (2D) topological surface states with a fourfold DC in a
first-order 3D TI, one-dimensional (1D) topological hinge states with a twofold
DC in a second-order 3D TI, and zero-dimensional (0D) topological corner states
in a third-order 3D TI. Our work not only expands the fundamental research
scope of Dirac physics, but also opens up a new route for multidimensional
robust wave manipulation."#
physics#physics#applied physics#Generating arbitrary laser beam shapes through phase-mapped designed  beam splitting#Pedro Faleiros Silva, Sérgio Ricardo Muniz#"We describe here a method to generate high-definition arbitrary laser beam
shapes and profiles useful to many applications, ranging from optical
patterning and lithography to optical trapping of microscopic particles and
ultracold atoms. The phase contrast between a binary grating and a targeted
intensity distribution is encoded on a spatial light modulator to control light
diffraction, producing very sharp, speckles-free, and smooth images. Besides
simplicity, not requiring additional phase-plates, the method provides
straightforward encoding of images onto phase-only masks by a direct pixel
mapping, allowing simpler feedback schemes to correct and control light
distributions and optical potentials in real-time."#
physics#physics#applied physics#Formation of bound states in the continuum in double trapezoidal grating#Yuhang Ruan, Jicheng Wang, Zheng-Da Hu, Yixiang Wang#"In the field of optics, bound state in the continuum (BIC) has been
researched in many photonic crystals and periodic structures due to a strong
resonance and an ultrahigh Q factor. Some designs of narrowband transmission
filters, lasers, and sensors were proposed based on excellent optical
properties of BIC. In this paper, we consider symmetrical rectangular grating
structure firstly, then cut off the corner of one of the gratings, the Fano
peak of quasi-BIC can be observed in the spectrum. After that, we further
change the tilt parameter of the other grating, which minimizes the Fano line
width. In the momentum space, the process of structural change corresponds to
topological charges split from q=1 into two half charges q=1/2.We analyze
guided mode resonance (GMR) excitation of the grating structure, and discuss
the dispersion relations in the waveguide layer with the position of BIC in
energy bands. In addition, the reflectance spectrum is found to exhibit
asymmetric line-shapes with different values of the asymmetry parameters, M1
and M2. BIC is transformed into quasi-BIC as the symmetry of the structure is
broken. This work demonstrates a double trapezoid structure with strong
resonance properties, which has significant implications for exploring the
phenomenon of BIC."#
physics#physics#applied physics#Scalability of gadolinium-doped-water Cherenkov detectors for nuclear  nonproliferation#Viacheslav A. Li, Steven A. Dazeley, Marc Bergevin, Adam Bernstein#"Antineutrinos are an unavoidable byproduct of the fission process. The
kton-scale KamLAND experiment has demonstrated the capability to detect reactor
antineutrinos at few-hundred-km range. But to detect or rule out the existence
of a single small reactor over many km requires a large detector. So large in
fact that the optical opacity of the detection medium itself becomes an
important factor. If the detector is so large that photons cannot traverse
across the detector medium to an optical detector, then it becomes impractical.
Gadolinium-doped water-Cherenkov detectors have been proposed for very large
reactor monitoring detectors. Even though Cherenkov emission does not produce
many photons and the energy resolution is poor, there may be a place for
Gd-doped water detectors for the largest of far-field detectors.
In this paper, we focus on the reactor discovery potential of large-volume
Gd-doped water-Cherenkov detectors for nuclear nonproliferation applications.
Realistic background models for the worldwide reactor flux, geo-neutrinos,
cosmogenic fast neutrons, and detector-associated backgrounds are included. We
calculate the detector run time required to detect a small 50-MWt reactor at a
variety of stand-off distances as a function of detector size. We highlight
that at present, PMT dark rate and event reconstruction algorithms are the
limiting factors to extending beyond ~50-kt fiducial mass."#
physics#physics#applied physics#Molecular beam homoepitaxy of N-polar AlN: enabling role of Al-assisted  surface cleaning#Zexuan Zhang, Yusuke Hayashi, Tetsuya Tohei, Akira Sakai, Vladimir Protasenko, Jashan Singhal, Hideto Miyake, Huili Grace Xing, Debdeep Jena, YongJin Cho#"N-polar aluminum nitride (AlN) is an important building block for
next-generation high-power RF electronics. We report successful homoepitaxial
growth of N-polar AlN by molecular beam epitaxy (MBE) on large-area
cost-effective N-polar AlN templates. Direct growth without any in-situ surface
cleaning leads to films with inverted Al-polarity. It is found that Al-assisted
cleaning before growth enables the epitaxial film to maintain N-polarity. The
grown N-polar AlN epilayer with its smooth, pit-free surface duplicates the
structural quality of the substrate as evidenced by a clean and smooth growth
interface with no noticeable extended defects generation. Near band-edge
photoluminescence peaks are observed at room temperature on samples with
MBE-grown layers but not on the bare AlN substrates, implying the suppression
of non-radiative recombination centers in the epitaxial N-polar AlN. These
results are pivotal steps towards future high-power RF electronics and deep
ultraviolet photonics based on the N-polar AlN platform."#
physics#physics#applied physics#Membrane-electrode assemblies for flow-electrode capacitive deionization#Christian Linnartz, Alexandra Rommerskirchen, Joanna Walker, Janis Plankermann-Hajduk, Niklas Köller, Matthias Wessling#"Scale-up of flow-electrode capacitive deionization is hindered due to the
reliance on thick brittle graphite current collectors. Inspired by developments
of electrochemical technologies we present the use of flexible membrane
electrode assemblies (MEA) to solve these limitations. We tested different
carbon-fiber fabrics as current collectors and laminated them successfully with
ion-exchange membranes. The use of thinner ion-exchange membranes is now
possible due to the reinforcement with the carbon fiber fabric. Desalination
experiments reveal that a MEA setup can achieve salt transfer rates equal to
standard setups. Hence, we deduce that charge percolation also acts outside the
electric field. In a single point of contact, ionic and electric charges are
exchanged at the carbon surface of the MEA. The use of thinner membranes leads
to a reduced potential drop. Together with a more homogeneous electric field
across the feed water section, this can compensate for the reduction of contact
surface between flow electrode and current collector."#
physics#physics#applied physics#Photonic interface for long-distance entanglement of logical-qubits#Mohammadsadegh Khazali#"A scalable fault-tolerant quantum-computer hardware with current noisy
intermediate-scale quantum (NISQ) devices requires the juxtaposition of
different types of quantum systems. In this sense, long-distance entanglement
of stationary error-corrected logical qubits requires a photonic bus
facilitating inter/intra-connection among the cores of quantum processors, the
units of quantum memories, and the worldwide quantum internet. This article
proposes a photonic interface for 4 and 6-qubit encoding of surface-code
logical-qubits in an atomic-lattice platform. Accommodating the lattice inside
a cavity, the gate emits photonic-qubits that are entangled by the
logical-qubits. The entangling mechanism is provided by the Fermi scattering of
a Rydberg electron from the plaquette atoms trapped in a qubit-dependent
lattice. Therefore, different arrangements of logical-qubits derive the central
atom over distinguished eigenstates, featuring photon emission at the early or
late times distinguished by quantum interference. Finally, entanglement
swapping of two emitted photons would make the far separated plaquettes
entangled in the logical basis."#
physics#physics#applied physics#The influence of phonon harmonicity on spectrally pure resonant Stokes  fields#Georgios Stoikos, Eduardo Granados#"Thanks to their highly coherent emission and compact form factor, single
axial mode diamond Raman lasers have been identified as a valuable asset for
applications including integrated quantum technology, high resolution
spectroscopy or coherent optical communications. While the fundamental emission
linewidth of these lasers can be Fourier limited, their thermo-optic
characteristics lead to drifts in their carrier frequency, posing important
challenges for applications requiring ultra-stable emission. We propose here a
method for measuring accurately the temperature-dependent index of refraction
of diamond by employing standing Stokes waves produced in a monolithic
Fabry-Perot (FP) diamond Raman resonator. Our approach takes into account the
influence of the temperature on the first-order phonon line and the average
lattice phonon frequency under intense stimulated Raman scattering (SRS)
conditions. We further utilize this model to calculate the
temperature-dependent thermo-optic coefficient and the Gruneisen parameter of
diamond in the visible spectral range. The theory is accompanied by the
demonstration of tunable Fourier-limited Stokes nanosecond pulses with a
stabilized center frequency deviation of less than <4 MHz."#
physics#physics#applied physics#Cell barrier characterization in transwell inserts by electrical  impedance spectroscopy#Georg Linz, Suzana Djeljadini, Lea Steinbeck, Gurbet Köse, Fabian Kiessling, Matthias Wessling#"We describe an impedance-based method for cell barrier integrity testing. A
four-electrode electrical impedance spectroscopy (EIS) setup can be realized by
simply connecting a commercial chopstick-like electrode (STX-1) to a
potentiostat allowing monitoring cell barriers cultivated in transwell inserts.
Subsequent electric circuit modeling of the electrical impedance results the
capacitive properties of the barrier next to the well-known transepithelial
electrical resistance (TEER). The versatility of the new method was analyzed by
the EIS analysis of a Caco-2 monolayer in response to (a) different membrane
coating materials, (b) two different permeability enhancers ethylene
glycol-bis(2-aminoethylether)-N,N,N',N'-tetraacetic acid (EGTA) and saponin,
and (c) sonoporation. For the different membrane coating materials, the TEERs
of the standard and new protocol coincide and increase during cultivation,
while the capacitance shows a distinct maximum for three different surface
materials (no coating, Matrigel, and collagen I). The permeability enhancers
cause a decline in the TEER value, but only saponin alters the capacitance of
the cell layer by two orders of magnitude. Hence, cell layer capacitance and
TEER represent two independent properties characterizing the monolayer. The use
of commercial chopstick-like electrodes to access the impedance of a barrier
cultivated in transwell inserts enables remarkable insight into the behavior of
the cellular barrier with no extra work for the researcher. This simple method
could evolve into a standard protocol used in cell barrier research."#
physics#physics#applied physics#Flow-electrode capacitive deionization enables continuous and  energy-efficient brine concentration#Alexandra Rommerskirchen, Christian Linnartz, Franziska Egidi, Sefkan Kendir, Matthias Wessling#"Many industrial and agricultural applications require the treatment of water
streams containing high concentrations of ionic species for closing material
cycles. High concentration factors are often desired, but hard to achieve with
established thermal or membrane-based water treatment technologies at low
energy consumptions. Capacitive deionization processes are normally assumed as
relevant for the treatment of low salinity solutions only. Flow-electrode
capacitive deionization (FCDI), on the other hand, is an electrically driven
water desalination technology, which allows the continuous desalination and
concentration of saline water streams even at elevated salinities. Ions are
adsorbed electrostatically in pumpable carbon flow electrodes, which enable a
range of new process designs.
In this article, it is shown that continuously operated FCDI systems can be
applied for the treatment of salt brines. Concentrations of up to 291.5~g/L
NaCl were reached in the concentrate product stream. Based on this, FCDI is a
promising technology for brine treatment and salt recovery. Additionally, a
reduction of the energy demand by more than 70% is demonstrated by introducing
multiple cell pairs into a continuous FCDI system. While the economic
feasibility is not investigated here, the results show that FCDI systems may
compete with established technologies regarding their energy demand."#
physics#physics#applied physics#Large Hall electron mobilities in head-to-head BaTiO$_3$-domain walls#Henrik Beccard, Benjamin Kirbus, Elke Beyreuther, Michael Rüsing, Petr Bednyakov, Jirka Hlinka, Lukas M. Eng#"Strongly charged head-to-head (H2H) domain walls (DWs) that are purposely
engineered along the [110] crystallographic orientation into ferroelectric
BaTiO$_3$ single crystals have been proposed as novel 2-dimensional electron
gases (2DEGs) due to their significant domain wall conductivity (DWC). Here, we
quantify these 2DEG properties through dedicated Hall-transport measurements in
van-der-Pauw 4-point geometry at room temperature, finding the electron
mobility to reach around 400~cm$^2$(Vs)$^{-1}$, while the 2-dimensional charge
density amounts to ~7$\times$10$^3$cm$^{-2}$. We underline the necessity to
take account of thermal and geometrical-misalignment offset voltages by
evaluating the Hall resistance under magnetic-field sweeps, since otherwise
dramatic errors of several hundred percent in the derived mobility and charge
density values can occur. Apart from the specific characterization of the
conducting BaTiO$_3$ DW, we propose the method as an easy and fast way to
quantitatively characterize ferroic conducting DWs, complementary to previously
proposed scanning-probe-based Hall-potential analyses."#
physics#physics#applied physics#N-polar GaN p-n junction diodes with low ideality factors#Kazuki Nomoto, Huili Grace Xing, Debdeep Jena, YongJin Cho#"High-quality N-polar GaN p-n diodes are realized on single-crystal N-polar
GaN bulk substrate by plasma-assisted molecular beam epitaxy. The
room-temperature current-voltage characteristics reveal a high on/off current
ratio of 10^11 at 4 V and an ideality factor of 1.6. As the temperature
increases to 200 C, the apparent ideality factor gradually approaches 2. At
such high temperatures, a Shockley-Read-Hall recombination time of 0.5 ns is
estimated. The measured electroluminescence spectrum is dominated by a strong
near-band edge emission, while deep level and acceptor-related luminescence is
greatly suppressed. A relatively high reverse breakdown field of 2.4 MV/cm
without field-plates is achieved. This work indicates that the quality of
N-polar GaN diodes is now approaching to that of their state-of-the-art
Ga-polar counterparts."#
physics#physics#applied physics#Rational design of carbon-based materials for purification and storage  of energy carrier gases of methane and hydrogen#Shohreh Mirzaei, Ali Ahmadpour, Zongping Shao, Arash Arami-Niya#"Today, fast-growing energy demands and fuel resource depletion are among the
hottest concerning issues that treating our world. So, a huge need is felt to
find efficient, affordable and eco-friendly energy storage and production
systems. Much current research effort proved that gaseous energy carriers such
as CH4 and H2 seem to be the right choice for alternative fuel resources.
However, the most important challenge with this new-faced resource is the
comparatively low volumetric energy storage density. Fortunately, the
high-pressure gas storage technique inside the porous media of solid adsorbent
is considered as one best way to tackle the energy density problem. Famous
family of porous carbon materials, with a suitable pore size distribution
centred in the micropore range and a large number of adsorption sites per
volume of solid, open up a great scope for gas storing applications. This
review article represents the state-of-the-art with a precise focus on what has
and can be done to improve/enhance the gas/energy storage capacity of
traditional and novel structures of low-cost carbon-based adsorbents. We review
a wide variety of design strategies to synthesis carbonaceous adsorbents, with
a strong focus on creating the connection between structural properties and gas
adsorption performance. In this regard, various synthesis techniques have been
studied with emphasis on the more interesting recent progress that allows
better control and optimisation of porosity of porous carbons for maxing gas
storage capacity. We will also show that carbon-based adsorbents, particularly
activated carbons, have been extensively studied and remain a powerful
candidate in the search for an energy carrier economy. In the end, a
perspective is provided to forecast the future development of carbon-based
materials."#
physics#physics#applied physics#Polarization-independent resonant lattice Kerker effect enabled by  phase-change material#Lei Xiong, Xiaoqing Luo, Hongwei Ding, Yuanfu Lu, Guangyuan Li#"Resonant lattice Kerker effect in periodic resonators is one of the most
interesting generalizations of the Kerker effect that relates to various
fascinating functionalities such as scattering management and Huygens
metasurfaces. However, so far this effect has been shown to be sensitive to the
incident polarization, restricting its applications. Here, we report, for the
first time, polarization-independent resonant lattice Kerker effect in
metasurfaces composed of periodic Ge$_2$Se$_2$Te$_5$ (GST) disks. For such a
metasurface of square lattice, the spectrally overlap of the electric dipole
and magnetic dipole surface lattice resonances can be realized by choosing an
appropriate GST crystalline fraction regardless of the incident polarization.
The operation wavelength and the required GST crystalline fraction can be
conveniently tuned over large ranges since these parameters scale linearly with
the disk size and the lattice period, greatly facilitating the design. Making
use of the obtained resonant lattice Kerker effect, we realize a reconfigurable
and polarization-independent lattice Huygens' metasurface with a dynamic phase
modulation of close to $2\pi$ and high transmittance. This work will advance
the engineering of the resonant lattice Kerker effect and promote its
applications in phase modulation and wavefront control."#
physics#physics#applied physics#One-transmitter Multiple-receiver Wireless Power Transfer System Using  an Exceptional Point of Degeneracy#Fatemeh Mohseni, Alireza Nikzamir, Hung Cao, Filippo Capolino#"Robust transfer efficiency against the various operating conditions in a
wireless power transfer system remains a fundamentally important challenge.
This challenge becomes even more critical when transferring power to groups of
inductively coupled receivers. We propose a method for efficient wireless power
transfer to multiple receivers exploiting the concept of exceptional points of
degeneracy (EPD). In previous studies based on PT symmetry, a receiver's
operation has been divided into two strong and weak coupling regimes, and the
power transfer efficiency is constant in the strong coupling regime when
varying the coupling factor.Here the concept of strong and weak coupling and
constant power efficiency is extended to a system of multiple receivers that do
not follow PT symmetry. We show that the important feature to have a roughly
constant power efficiency, independently of the positions of the receivers, is
the existence of an EPD that separates the weak and strong regimes. Our
proposed method demonstrates a system with less sensitivity to the coupling
change than a conventional system without EPD when the receivers and their
couplings to the transmitter are not necessarily identical."#
physics#physics#applied physics#Failure Mode Analysis in Microsecond UV Laser Annealing of Cu Thin Films#Remi Demoulin, Richard Daubriac, Louis Thuries, Emmanuel Scheid, Fabien Rozé, Fuccio Cristiano, Toshiyuki Tabata, Fulvio Mazzamuto#"The need of surface-localized thermal processing is strongly increasing
especially w.r.t three-dimensionally (3D) integrated electrical devices. UV
laser annealing (UV-LA) technology well addresses this challenge. Particularly
UV-LA can reduce resistivity by enlarging metallic grains in lines or thin
films, irradiating only the interconnects for short timescales. However, the
risk of failure in electrical performance must be correctly managed, and that
of UV-LA has not been deeply studied yet. In this work microsecond-scale UV-LA
is applied on a stack comparable to an interconnect structure
(dielectric/Cu/Ta/SiO2/Si) in either melt or sub-melt regime for grain growth.
The failure modes such as (i) Cu diffusion into SiO2, (ii) O incorporation into
Cu, and (iii) intermixing between Cu and Ta are investigated."#
physics#physics#applied physics#Designing Multi-functional Metamaterials#J. R. Capers, S. J. Boyes, A. P. Hibbins, S. A. R. Horsley#"The ability to design passive structures that perform different operations on
different electromagnetic fields is key to many technologies, from
beam-steering to optical computing. While many techniques have been developed
to optimise structure to achieve specific functionality through inverse design,
designing multi-function materials remains challenging. We present a
semi-analytic method, based on the discrete dipole approximation, to design
multi-functional metamaterials. To demonstrate the generality of our method, we
design a device that operates at optical wavelengths and beams light into
different directions depending on the source polarisation and a device that
works at microwave wavelengths and sorts plane waves by their angle of
incidence."#
physics#physics#applied physics#Phase-field simulations of the morphology formation in evaporating  crystalline multicomponent films#Olivier J.J. Ronsin, Jens Harting#"In numerous solution-processed thin films, a complex morphology resulting
from liquid-liquid phase separation (LLPS) or from polycrystallization arises
during the drying or subsequent processing steps. The morphology has a strong
influence on the performance of the final device but unfortunately the
process-structure relationship is often poorly and only qualitatively
understood. This is because many different physical mechanisms (miscibility,
evaporation, crystallization, diffusion, advection) are active at potentially
different time scales, and because the kinetics plays a crucial role: the
morphology develops until it is kinetically quenched far from equilibrium. In
order to unravel the various possible structure formation pathways, we propose
a unified theoretical framework that takes into account all these physical
phenomena. This phase-field simulation tool is based on the Cahn-Hilliard
equations for diffusion and the Allen-Cahn equation for crystallization and
evaporation, which are coupled to the equations for the dynamics of the fluid.
We discuss and validate the behavior of the coupled model based on simple test
cases. Furthermore, we illustrate how this framework allows to investigate the
morphology formation in a drying film undergoing evaporation-induced LLPS and
crystallization, which is typically a situation encountered, e.g., in organic
photovoltaics applications."#
mathematics#mathematics#functional analysis#Composition operators on weighted Hilbert spaces of Dirichlet series#Athanasios Kouroupis, Karl-Mikael Perfekt#"We study composition operators of characteristic zero on weighted Hilbert
spaces of Dirichlet series. For this purpose we demonstrate the existence of
weighted mean counting functions associated with the Dirichlet series symbol,
and provide a corresponding change of variables formula for the composition
operator. This leads to natural necessary conditions for the boundedness and
compactness. For Bergman-type spaces, we are able to show that the compactness
condition is also sufficient, by employing a Schwarz-type lemma for Dirichlet
series."#
mathematics#mathematics#functional analysis#Symmetrization inequalities on one-dimensional integer lattice#Shubham Gupta#"In this paper, we develop a theory of symmetrization on the one dimensional
integer lattice. More precisely, we associate a radially decreasing function
$u^*$ with a function $u$ defined on the integers and prove the corresponding
Polya-Szeg\""{o} inequality. Along the way we also prove the weighted
Polya-Szeg\""{o} inequality for the decreasing rearrangement on the half-line,
i.e., non-negative integers. As a consequence, we prove the discrete weighted
Hardy's inequality with the weight $n^\alpha$ for $1 < \alpha \leq 2$."#
mathematics#mathematics#functional analysis#The polar decomposition for the product of three operators#Dingyi Du, Qingxiang Xu, Shuo Zhao#"In the setting of adjointable operators on Hilbert $C^*$-modules, this paper
deals with the polar decomposition of the product of three operators. The
relationship between the polar decompositions associated with three operators
is clarified. Based on this relationship, a formula for the polar decomposition
of a multiplicative perturbation of an operator is provided. In addition, some
characterizations of the polar decomposition associated with three operators
are provided."#
mathematics#mathematics#functional analysis#A Variant of the Kaplansky Problem for Maps on Positive Matrices#Mateo Tomašević#"We prove that all injective maps on positive complex matrices which preserve
order and shrink spectrum are implemented by unitary or antiunitary
conjugations. We show by counterexamples that all assumptions are
indispensable. The result easily generalizes to maps on hermitian matrices."#
mathematics#mathematics#functional analysis#BMO with respect to Banach function spaces#Andrei K. Lerner, Emiel Lorist, Sheldy Ombrosi#"For every cube $Q \subset \mathbb{R}^n$ we let $X_Q$ be a quasi-Banach
function space over $Q$ such that $\|\chi_Q\|_{X_Q} \simeq 1$, and for $X=
\{X_Q\}$ define \begin{align*} \|f\|_{\mathrm{BMO}_X} &:=\sup_Q
\,\|f-{\textstyle\frac{1}{|Q|}\int_Qf} \|_{X_Q},\\ \|f\|_{\mathrm{BMO}_X^*}
&:=\sup_Q \,\inf_c\, \|f-c\|_{X_Q}. \end{align*} We study necessary and
sufficient conditions on $X$ such that $$ \mathrm{BMO} = \mathrm{BMO}_X =
\mathrm{BMO}_{X}^*. $$ In particular, we give a full characterization of the
embedding $\mathrm{BMO} \hookrightarrow \mathrm{BMO}_X$ in terms of so-called
sparse collections of cubes and we give easily checkable and rather weak
sufficient conditions for the embedding $\mathrm{BMO}_X^* \hookrightarrow
\mathrm{BMO}$. Our main theorems recover and improve all previously known
results in this area."#
mathematics#mathematics#functional analysis#Linear topological invariants for kernels of convolution and  differential operators#Andreas Debrouwere, Thomas Kalmes#"We establish the condition $(\Omega)$ for smooth kernels of various types of
convolution and differential operators. By the $(DN)$-$(\Omega)$ splitting
theorem of Vogt and Wagner, this implies that these operators are surjective on
the corresponding spaces of vector-valued smooth functions with values in a
product of Montel $(DF)$-spaces whose strong duals satisfy the condition
$(DN)$, e.g., the space $\mathscr{D}'(X)$ of distributions over an open set $X
\subseteq \mathbb{R}^d$ or the space $\mathscr{S}'(\mathbb{R}^d)$ of tempered
distributions. Most notably, we show that:
$(i)$ $\mathscr{E}_P(X) = \{ f \in \mathscr{E}(X) \, | \, P(D)f = 0 \}$
satisfies $(\Omega)$ for any differential operator $P(D)$ and any open convex
set $X \subseteq \mathbb{R}^d$.
$(ii)$ Let $P\in\mathbb{C}[X_1,X_2]$ and $X \subseteq \mathbb{R}^2$ open be
such that $P(D):\mathscr{E}(X)\rightarrow\mathscr{E}(X)$ is surjective. Then,
$\mathscr{E}_P(X)$ satisfies $(\Omega)$.
$(iii)$ Let $\mu \in \mathscr{E}'(\mathbb{R}^d)$ be such that $
\mathscr{E}(\mathbb{R}^d) \rightarrow \mathscr{E}(\mathbb{R}^d), \, f \mapsto
\mu \ast f$ is surjective. Then, $ \{ f \in \mathscr{E}(\mathbb{R}^d) \, | \,
\mu \ast f = 0 \}$ satisfies $(\Omega)$.
The central result in this paper states that the space of smooth zero
solutions of a general convolution equation satisfies the condition $(\Omega)$
if and only if the space of distributional zero solutions of the equation
satisfies the condition $(P\Omega)$. The above and related results then follow
from known results concerning $(P\Omega)$ for distributional kernels of
convolution and differential operators."#
mathematics#mathematics#functional analysis#Characterizations of variable fractional Hajłasz-Sobolev spaces#Xiaosi Zhang, Qi Sun#"Let (X, \r{ho},\mu) be a space of homogeneous type, a variable exponent
satisfying the globally log-Holder continuous condition. In this article, the
author introduce the variable fractional Sobolev spaces on X via Haj{\l}asz
gradient. Using various maximal functions, several characterizations of this
space are established."#
mathematics#mathematics#functional analysis#A note on the dilation of a certain family of tetrablock contractions#Tirthankar Bhattacharyya, Mainak Bhowmik#"We find explicit tetrablock isometric dilation for every member $(A_\alpha,
B, P)$ of a family of tetrablock contractions indexed by a parameter $\alpha$
in the closed unit disc (only the first operator of the tetrablock contraction
depends on the parameter). The dilation space is the same for any member of the
family and the dilation is not minimal. Explicit dilation for the adjoint
tetrablock contraction $(A_\alpha^*, B^*, P^*)$ for every member of the family
mentioned above is constructed as well. This family includes the example
considered in Section 5 of \cite{Pal}. Taking cue from this construction and
using Toeplitz operators on $H^2_{\mathbb D}(\mathcal D_P)$, we obtain
necessary and sufficient conditions for a tetrablock contraction to have a
certain type of tetrablock isometric dilation."#
mathematics#mathematics#functional analysis#Cyclic cohomology and the extended Heisenberg calculus of Epstein and  Melrose#Alexander Gorokhovsky, Erik van Erp#"In this paper we present a formula for the index of a pseudodifferential
operator with invertible principal symbol in the extended Heisenberg calculus
of Epstein and Melrose. Our results build on the work we did in a previous
paper (), where we restricted attention to the Heisenberg
calculus proper."#
mathematics#mathematics#functional analysis#Energy decay estimates for the wave equation with supercritical  nonlinear damping#Alain Haraux, Louis Tebou#"We consider a damped wave equation in a bounded domain. The damping is
nonlinear and is homogeneous with degree p -- 1 with p > 2. First, we show that
the energy of the strong solution in the supercritical case decays as a
negative power of t; the rate of decay is the same as in the subcritical or
critical cases, provided that the space dimension does not exceed ten. Next,
relying on a new differential inequality, we show that if the initial
displacement is further required to lie in L p , then the energy of the
corresponding weak solution decays logarithmically in the supercritical case.
Those new results complement those in the literature and open an important
breach in the unknown land of super-critical damping mechanisms."#
mathematics#mathematics#functional analysis#Complex valued semi-linear heat equations in super-critical spaces  $E^s_σ$#Jie Chen, Baoxiang Wang, Zimeng Wang#"We consider the Cauchy problem for the complex valued semi-linear heat
equation $$
\partial_t u - \Delta u - u^m =0, \ \ u (0,x) = u_0(x), $$ where $m\geq 2$ is
an integer and the initial data belong to super-critical spaces $E^s_\sigma$
for which the norms are defined by $$ \|f\|_{E^s_\sigma} = \|\langle
\xi\rangle^\sigma 2^{s|\xi|}\widehat{f}(\xi)\|_{L^2}, \ \ \sigma \in
\mathbb{R}, \ s<0. $$ If $s<0$, then any Sobolev space $H^{r}$ is a subspace of
$E^s_\sigma$, i.e., $\cup_{r \in \mathbb{R}} H^r \subset E^s_\sigma$. We obtain
the global existence and uniqueness of the solutions if the initial data belong
to $E^s_\sigma$ ($s<0, \ \sigma \geq d/2-2/(m-1)$) and their Fourier transforms
are supported in the first octant, the smallness conditions on the initial data
in $E^s_\sigma$ are not required for the global solutions. Moreover, we show
that the error between the solution $u$ and the iteration solution $u^{(j)}$ is
$C^j/(j\,!)^2$. Similar results also hold if the nonlinearity $u^m$ is replaced
by an exponential function $e^u-1$."#
mathematics#mathematics#functional analysis#Piecewise-Linear Activations or Analytic Activation Functions: Which  Produce More Expressive Neural Networks?#Anastasis Kratsios, Behnoosh Zamanlooy#"Many currently available universal approximation theorems affirm that deep
feedforward networks defined using any suitable activation function can
approximate any integrable function locally in $L^1$-norm. Though different
approximation rates are available for deep neural networks defined using other
classes of activation functions, there is little explanation for the
empirically confirmed advantage that ReLU networks exhibit over their classical
(e.g. sigmoidal) counterparts. Our main result demonstrates that deep networks
with piecewise linear activation (e.g. ReLU or PReLU) are fundamentally more
expressive than deep feedforward networks with analytic (e.g. sigmoid, Swish,
GeLU, or Softplus). More specifically, we construct a strict refinement of the
topology on the space $L^1_{\operatorname{loc}}(\mathbb{R}^d,\mathbb{R}^D)$ of
locally Lebesgue-integrable functions, in which the set of deep ReLU networks
with (bilinear) pooling $\operatorname{NN}^{\operatorname{ReLU} +
\operatorname{Pool}}$ is dense (i.e. universal) but the set of deep feedforward
networks defined using any combination of analytic activation functions with
(or without) pooling layers $\operatorname{NN}^{\omega+\operatorname{Pool}}$ is
not dense (i.e. not universal). Our main result is further explained by
\textit{quantitatively} demonstrating that this ""separation phenomenon"" between
the networks in $\operatorname{NN}^{\operatorname{ReLU}+\operatorname{Pool}}$
and those in $\operatorname{NN}^{\omega+\operatorname{Pool}}$ by showing that
the networks in $\operatorname{NN}^{\operatorname{ReLU}}$ are capable of
approximate any compactly supported Lipschitz function while
\textit{simultaneously} approximating its essential support; whereas, the
networks in $\operatorname{NN}^{\omega+\operatorname{pool}}$ cannot."#
mathematics#mathematics#functional analysis#Non-commutative ambits and equivariant compactifications#Alexandru Chirvasitu#"We prove that an action $\rho:A\to M(C_0(\mathbb{G})\otimes A)$ of a locally
compact quantum group on a $C^*$-algebra has a universal equivariant
compactification, and prove a number of other category-theoretic results on
$\mathbb{G}$-equivariant compactifications: that the categories
compactifications of $\rho$ and $A$ respectively are locally presentable (hence
complete and cocomplete), that the forgetful functor between them is a
colimit-creating left adjoint, and that epimorphisms therein are surjective and
injections are regular monomorphisms.
When $\mathbb{G}$ is coamenable we also show that the forgetful functor from
unital $\mathbb{G}$-$C^*$-algebras to unital $C^*$-algebras creates finite
limits and is comonadic, and that the monomorphisms in the former category are
injective."#
mathematics#mathematics#functional analysis#A Generalization of q-Binomial Theorem#Qi Bao#"By using Liu's $q$-partial differential equations theory, we prove that if an
analytic function in several variables satisfies a system of $q$-partial
differential equations, if and only if it can be expanded in terms of
homogeneous $(q,c)$-Al-Salam-Carlitz polynomials. As an application, we proved
that for $c\neq0$ and $\max \{|cq|,|x|\}<1$, \begin{align*} \sum_{n=0}^{\infty}
\frac{ (a;q)_n }{(cq;q)_n}x^n=(ax/c;q)_{\infty} \sum_{n=0}^{\infty}
\frac{x^n}{(cq;q)_n}, \end{align*} which is a generalization of famous
$q$-binomial theorem or so-called Cauchy theorem."#
mathematics#mathematics#functional analysis#Nevanlinna counting functions and pull-back measures on maximal ideal  space of $H^\infty$#Yong-Xin Gao, Yuxia Liang, Ze-Hua Zhou#"In this paper we give precise characterizations of the relation between the
Nevanlinna counting function and pull-back measure of an analytic self-map of
the unit disk near the boundary. We show that it is quite worth considering
these two concepts on the maximal ideal space of the bounded analytic
functions."#
mathematics#mathematics#functional analysis#Density results and trace operator in weighted Sobolev Spaces defined on  the half line equipped with power weights#Radosław Kaczmarek, Agnieszka Kałamajska#"We study properties of $W_0^{1,p}(\mathbb{R}_+,t^\beta)$ - the completion of
$C_0^\infty(\mathbb{R}_+)$ in the power-weighted Sobolev spaces
$W^{1,p}(\mathbb{R}_+,t^\beta)$, where $\beta\in\mathbb{R}$. Among other
results, we obtain the analytic characterization of
$W_0^{1,p}(\mathbb{R}_+,t^\beta)$ for all $\beta\in \mathbb{R}$. Our analysis
is based on the precise study the two trace operators: $Tr^{0}(u):= \lim_{t\to
0} u(t)$ and $Tr^{\infty}(u):= \lim_{t\to \infty} u(t)$, which leads to the
analysis of the asymptotic behavior of functions from
$W_0^{1,p}(\mathbb{R}_+,t^\beta)$ near zero or infinity. The obtained
statements can contribute to the proper formulation of Boundary Value Problems
in ODE's, or PDE's with the radial symmetries. We can also apply our results to
some questions in the complex interpolation theory, raised by M. Cwikel and A.
Einav in 2019, which we discuss within the particular case of Sobolev spaces
$W^{1,p}(\mathbb{R}_+,t^\beta)$."#
mathematics#mathematics#functional analysis#Statistical $p$-convergence in lattice-normed Riesz spaces#Abdullah Aydın, Reha Yapalı, Erdal Korkmaz#"A sequence $(x_n)$ in a lattice-normed space $(X,p,E)$ is statistical
$p$-convergent to $x\in X$ if there exists a statistical $p$-decreasing
sequence $q\stpd 0$ with an index set $K$ such that $\delta(K)=1$ and
$p(x_{n_k}-x)\leq q_{n_k}$ for every $n_k\in K$. This convergence has been
investigated recently for $(X,p,E)=(E,|\cdot|,E)$ under the name of statistical
order convergence and under the name of statistical multiplicative order
convergence, and also, for taking $E$ as a locally solid Riesz space under the
names statistically unbounded $\tau$-convergence and statistically
multiplicative convergence. In this paper, we study the general properties of
statistical $p$-convergence."#
mathematics#mathematics#functional analysis#Compactness property of the linearized Boltzmann operator for a  polyatomic gas undergoing resonant collisions#Thomas Borsoni, Laurent Boudin, Francesco Salvarani#"In this paper, we investigate a compactness property of the linearized
Boltzmann operator in the context of a polyatomic gas whose molecules undergo
resonant collisions. The peculiar structure of resonant collision rules allows
to tensorize the problem into a velocity-related one, neighbouring the
monatomic case, and an internal energy-related one. Our analysis is based on a
specific treatment of the contributions due to the internal energy of the
molecules. We also propose a geometric variant of Grad's proof of the same
compactness property in the monatomic case."#
mathematics#mathematics#functional analysis#On solvability of dissipative partial differential-algebraic equations#Birgit Jacob, Kirsten Morris#"In this article we investigate the solvability of infinite-dimensional
differential algebraic equations. Such equations often arise as partial
differential-algebraic equations (PDAEs). A decomposition of the state-space
that leads to an extension of the Hille-Yosida Theorem on Hilbert spaces for
these equations is described. For dissipative partial differential equations
the famous Lumer-Phillips generation theorem characterizes solvability and also
boundedness of the associated semigroup. An extension of the Lumer-Phillips
generation theorem to dissipative differential-algebraic equations is given.
The results is illustrated by coupled systems and the Dzektser equation."#
>>>>>>> e7b8b23db5988ddd218b6275de838a3c7e89c2f8
